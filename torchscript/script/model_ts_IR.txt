module __torch__.ScriptableAdapter {
  parameters {
  }
  attributes {
    _is_full_backward_hook = None
    model = <__torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN object at 0xaaa8070>
  }
  methods {
    method forward {
      graph(%self : __torch__.ScriptableAdapter,
            %inputs.1 : (Dict(str, Tensor))):
        %12 : bool = prim::Constant[value=1]() # export_model.py:91:23
        %7 : NoneType = prim::Constant()
        %4 : bool = prim::Constant[value=0]() # export_model.py:90:72
        %model : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN = prim::GetAttr[name="model"](%self)
        %5 : Dict(str, Tensor) = prim::TupleUnpack(%inputs.1)
        %6 : Dict(str, Tensor)[] = prim::ListConstruct(%5)
        %instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="inference"](%model, %6, %7, %4) # export_model.py:90:28
        %9 : Dict(str, Tensor)[] = prim::ListConstruct()
        %11 : int = aten::len(%instances.1) # export_model.py:91:23
         = prim::Loop(%11, %12) # export_model.py:91:23
          block0(%13 : int):
            %i.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%instances.1, %13) # export_model.py:91:23
            %16 : Dict(str, Tensor) = prim::CallMethod[name="get_fields"](%i.1) # export_model.py:91:24
            %17 : Dict(str, Tensor)[] = aten::append(%9, %16) # export_model.py:91:23
            -> (%12)
        return (%9)
  
    }
  }
  submodules {
    module __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN {
      parameters {
      }
      attributes {
        pixel_mean = ...
        pixel_std = ...
        _is_full_backward_hook = None
        input_format = BGR
        vis_period = 0
        backbone = <__torch__.detectron2.modeling.backbone.fpn.FPN object at 0xaa8d540>
        proposal_generator = <__torch__.detectron2.modeling.proposal_generator.rpn.RPN object at 0xaae9e20>
        roi_heads = <__torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads object at 0x6285780>
      }
      methods {
        method __device_getter {
          graph(%self : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN):
            %pixel_mean : Tensor = prim::GetAttr[name="pixel_mean"](%self)
            %2 : Device = prim::device(%pixel_mean)
            return (%2)
      
        }
        method forward {
          graph(%self : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN,
                %batched_inputs.1 : Dict(str, Tensor)[]):
            %8 : bool = prim::Constant[value=1]()
            %7 : NoneType = prim::Constant()
            %9 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="inference"](%self, %batched_inputs.1, %7, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:150:19
            return (%9)
      
        }
        method inference {
          graph(%self : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN,
                %batched_inputs.1 : Dict(str, Tensor)[],
                %detected_instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]?,
                %do_postprocess.1 : bool):
            %86 : str = prim::Constant[value="AssertionError: Scripting is not supported for postprocess."]()
            %41 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:215:33
            %15 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:206:33
            %images.1 : __torch__.detectron2.structures.image_list.ImageList = prim::CallMethod[name="preprocess_image"](%self, %batched_inputs.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:203:17
            %backbone : __torch__.detectron2.modeling.backbone.fpn.FPN = prim::GetAttr[name="backbone"](%self)
            %tensor : Tensor = prim::GetAttr[name="tensor"](%images.1)
            %features.1 : Dict(str, Tensor) = prim::CallMethod[name="forward"](%backbone, %tensor) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:204:19
            %16 : bool = aten::__is__(%detected_instances.1, %15) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:206:11
            %results : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::If(%16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:206:8
              block0():
                %proposal_generator : __torch__.detectron2.modeling.proposal_generator.rpn.RPN = prim::GetAttr[name="proposal_generator"](%self)
                %24 : (__torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], Dict(str, Tensor)) = prim::CallMethod[name="forward"](%proposal_generator, %images.1, %features.1, %15) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:208:31
                %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], %26 : Dict(str, Tensor) = prim::TupleUnpack(%24)
                %roi_heads.1 : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads = prim::GetAttr[name="roi_heads"](%self)
                %32 : (__torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], Dict(str, Tensor)) = prim::CallMethod[name="forward"](%roi_heads.1, %images.1, %features.1, %proposals.1, %15) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:213:25
                %results.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], %34 : Dict(str, Tensor) = prim::TupleUnpack(%32)
                -> (%results.1)
              block1():
                %detected_instances.7 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::unchecked_cast(%detected_instances.1)
                %detected_instances.13 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::ListConstruct()
                %40 : int = aten::len(%detected_instances.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:215:33
                 = prim::Loop(%40, %41) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:215:33
                  block0(%42 : int):
                    %x.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%detected_instances.7, %42) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:215:33
                    %45 : Device = prim::CallMethod[name="__device_getter"](%self) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:215:39
                    %46 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = prim::CallMethod[name="to"](%x.1, %45) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:215:34
                    %47 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = aten::append(%detected_instances.13, %46) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:215:33
                    -> (%41)
                %roi_heads : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads = prim::GetAttr[name="roi_heads"](%self)
                %results.3 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="forward_with_given_boxes"](%roi_heads, %features.1, %detected_instances.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:216:22
                -> (%results.3)
             = prim::If(%do_postprocess.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:218:8
              block0():
                 = prim::RaiseException(%86) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:219:12
                -> ()
              block1():
                -> ()
            return (%results)
      
        }
        method preprocess_image {
          graph(%self : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN,
                %batched_inputs.1 : Dict(str, Tensor)[]):
            %33 : Function = prim::Constant[name="from_tensors"]()
            %32 : float = prim::Constant[value=0.]()
            %22 : int = prim::Constant[value=1]()
            %10 : str = prim::Constant[value="image"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:227:49
            %6 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:227:17
            %images.1 : Tensor[] = prim::ListConstruct()
            %5 : int = aten::len(%batched_inputs.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:227:17
             = prim::Loop(%5, %6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:227:17
              block0(%7 : int):
                %x.1 : Dict(str, Tensor) = aten::__getitem__(%batched_inputs.1, %7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:227:17
                %11 : Tensor = aten::__getitem__(%x.1, %10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:227:47
                %12 : Tensor = prim::CallMethod[name="_move_to_current_device"](%self, %11) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:227:18
                %13 : Tensor[] = aten::append(%images.1, %12) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:227:17
                -> (%6)
            %images.5 : Tensor[] = prim::ListConstruct()
            %16 : int = aten::len(%images.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:228:17
             = prim::Loop(%16, %6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:228:17
              block0(%18 : int):
                %x.5 : Tensor = aten::__getitem__(%images.1, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:228:17
                %pixel_mean : Tensor = prim::GetAttr[name="pixel_mean"](%self)
                %23 : Tensor = aten::sub(%x.5, %pixel_mean, %22) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:228:19
                %pixel_std : Tensor = prim::GetAttr[name="pixel_std"](%self)
                %25 : Tensor = aten::div(%23, %pixel_std) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:228:19
                %26 : Tensor[] = aten::append(%images.5, %25) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:228:17
                -> (%6)
            %backbone.1 : __torch__.detectron2.modeling.backbone.fpn.FPN = prim::GetAttr[name="backbone"](%self)
            %29 : int = prim::CallMethod[name="__size_divisibility_getter"](%backbone.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:231:12
            %backbone : __torch__.detectron2.modeling.backbone.fpn.FPN = prim::GetAttr[name="backbone"](%self)
            %31 : Dict(str, int) = prim::CallMethod[name="__padding_constraints_getter"](%backbone) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:232:32
            %images.9 : __torch__.detectron2.structures.image_list.ImageList = prim::CallFunction(%33, %images.5, %29, %32, %31) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:229:17
            return (%images.9)
      
        }
        method _move_to_current_device {
          graph(%self : __torch__.detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN,
                %x.1 : Tensor):
            %4 : Function = prim::Constant[name="move_device_like"]()
            %pixel_mean : Tensor = prim::GetAttr[name="pixel_mean"](%self)
            %5 : Tensor = prim::CallFunction(%4, %x.1, %pixel_mean) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/meta_arch/rcnn.py:89:15
            return (%5)
      
        }
      }
      submodules {
        module __torch__.detectron2.modeling.backbone.fpn.FPN {
          parameters {
          }
          attributes {
            _is_full_backward_hook = None
            in_features = (res2, res3, res4, res5)
            _out_feature_strides = {p2: 4, p3: 8, p4: 16, p5: 32, p6: 64}
            _out_features = [p2, p3, p4, p5, p6]
            _out_feature_channels = {p2: 256, p3: 256, p4: 256, p5: 256, p6: 256}
            _size_divisibility = 32
            _square_pad = 0
            top_block = <__torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool object at 0x1213f7a0>
            bottom_up = <__torch__.detectron2.modeling.backbone.resnet.ResNet object at 0x9b716d0>
            lateral_convs = <__torch__.torch.nn.modules.container.___torch_mangle_37.ModuleList object at 0xaae6600>
            output_convs = <__torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList object at 0x9b70640>
          }
          methods {
            method __padding_constraints_getter {
              graph(%self : __torch__.detectron2.modeling.backbone.fpn.FPN):
                %1 : str = prim::Constant[value="square_size"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:124:16
                %_square_pad : int = prim::GetAttr[name="_square_pad"](%self)
                %3 : Dict(str, int) = prim::DictConstruct(%1, %_square_pad)
                return (%3)
          
            }
            method __size_divisibility_getter {
              graph(%self : __torch__.detectron2.modeling.backbone.fpn.FPN):
                %_size_divisibility : int = prim::GetAttr[name="_size_divisibility"](%self)
                return (%_size_divisibility)
          
            }
            method forward {
              graph(%self : __torch__.detectron2.modeling.backbone.fpn.FPN,
                    %x.1 : Tensor):
                %290 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:167:15
                %347 : str = prim::Constant[value="AssertionError: "]()
                %345 : int = prim::Constant[value=-4]()
                %341 : int = prim::Constant[value=-3]()
                %131 : int = prim::Constant[value=1]()
                %125 : Function = prim::Constant[name="interpolate"]()
                %122 : NoneType = prim::Constant()
                %119 : str = prim::Constant[value="nearest"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:153:88
                %337 : int = prim::Constant[value=-2]()
                %21 : int = prim::Constant[value=-1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:141:82
                %idx.1 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:141:43
                %71 : float = prim::Constant[value=2.]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:153:78
                %bottom_up : __torch__.detectron2.modeling.backbone.resnet.ResNet = prim::GetAttr[name="bottom_up"](%self)
                %bottom_up_features.1 : Dict(str, Tensor) = prim::CallMethod[name="forward"](%bottom_up, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:139:29
                %results.1 : Tensor[] = prim::ListConstruct()
                %lateral_convs.1 : __torch__.torch.nn.modules.container.___torch_mangle_37.ModuleList = prim::GetAttr[name="lateral_convs"](%self)
                %_0.1 : __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d = prim::GetAttr[name="0"](%lateral_convs.1)
                %in_features.1 : (str, str, str, str) = prim::GetAttr[name="in_features"](%self)
                %22 : str = prim::TupleIndex(%in_features.1, %21)
                %23 : Tensor = aten::__getitem__(%bottom_up_features.1, %22) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:141:46
                %prev_features.1 : Tensor = prim::CallMethod[name="forward"](%_0.1, %23) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:141:24
                %output_convs.1 : __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList = prim::GetAttr[name="output_convs"](%self)
                %_0.3 : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d = prim::GetAttr[name="0"](%output_convs.1)
                %36 : Tensor = prim::CallMethod[name="forward"](%_0.3, %prev_features.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:142:23
                %37 : Tensor[] = aten::append(%results.1, %36) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:142:8
                %lateral_convs : __torch__.torch.nn.modules.container.___torch_mangle_37.ModuleList = prim::GetAttr[name="lateral_convs"](%self)
                %_1.5 : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d = prim::GetAttr[name="1"](%lateral_convs)
                %_2.5 : __torch__.detectron2.layers.wrappers.___torch_mangle_35.Conv2d = prim::GetAttr[name="2"](%lateral_convs)
                %_3.5 : __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d = prim::GetAttr[name="3"](%lateral_convs)
                %output_convs : __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList = prim::GetAttr[name="output_convs"](%self)
                %_1 : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d = prim::GetAttr[name="1"](%output_convs)
                %_2 : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d = prim::GetAttr[name="2"](%output_convs)
                %_3 : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d = prim::GetAttr[name="3"](%output_convs)
                %in_features.5 : (str, str, str, str) = prim::GetAttr[name="in_features"](%self)
                %features.9 : str = prim::TupleIndex(%in_features.5, %337)
                %features.13 : Tensor = aten::__getitem__(%bottom_up_features.1, %features.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:152:27
                %top_down_features.5 : Tensor = prim::CallFunction(%125, %prev_features.1, %122, %71, %119, %122, %122) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:153:36
                %lateral_features.5 : Tensor = prim::CallMethod[name="forward"](%_1.5, %features.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:154:35
                %prev_features.37 : Tensor = aten::add(%lateral_features.5, %top_down_features.5, %131) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:155:32
                %147 : Tensor = prim::CallMethod[name="forward"](%_1, %prev_features.37) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:158:34
                 = aten::insert(%results.1, %idx.1, %147) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:158:16
                %in_features.7 : (str, str, str, str) = prim::GetAttr[name="in_features"](%self)
                %features.17 : str = prim::TupleIndex(%in_features.7, %341)
                %features.21 : Tensor = aten::__getitem__(%bottom_up_features.1, %features.17) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:152:27
                %top_down_features.9 : Tensor = prim::CallFunction(%125, %prev_features.37, %122, %71, %119, %122, %122) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:153:36
                %lateral_features.9 : Tensor = prim::CallMethod[name="forward"](%_2.5, %features.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:154:35
                %prev_features.67 : Tensor = aten::add(%lateral_features.9, %top_down_features.9, %131) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:155:32
                %193 : Tensor = prim::CallMethod[name="forward"](%_2, %prev_features.67) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:158:34
                 = aten::insert(%results.1, %idx.1, %193) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:158:16
                %in_features : (str, str, str, str) = prim::GetAttr[name="in_features"](%self)
                %features.25 : str = prim::TupleIndex(%in_features, %345)
                %features.29 : Tensor = aten::__getitem__(%bottom_up_features.1, %features.25) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:152:27
                %top_down_features.13 : Tensor = prim::CallFunction(%125, %prev_features.67, %122, %71, %119, %122, %122) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:153:36
                %lateral_features.13 : Tensor = prim::CallMethod[name="forward"](%_3.5, %features.29) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:154:35
                %prev_features.97 : Tensor = aten::add(%lateral_features.13, %top_down_features.13, %131) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:155:32
                %240 : Tensor = prim::CallMethod[name="forward"](%_3, %prev_features.97) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:158:34
                 = aten::insert(%results.1, %idx.1, %240) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:158:16
                %top_block.3 : __torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool = prim::GetAttr[name="top_block"](%self)
                %in_feature.1 : str = prim::GetAttr[name="in_feature"](%top_block.3)
                %252 : bool = aten::__contains__(%bottom_up_features.1, %in_feature.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:161:15
                %top_block_in_feature : Tensor = prim::If(%252) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:161:12
                  block0():
                    %top_block.5 : __torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool = prim::GetAttr[name="top_block"](%self)
                    %in_feature.3 : str = prim::GetAttr[name="in_feature"](%top_block.5)
                    %top_block_in_feature.1 : Tensor = aten::__getitem__(%bottom_up_features.1, %in_feature.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:162:39
                    -> (%top_block_in_feature.1)
                  block1():
                    %_out_features.1 : str[] = prim::GetAttr[name="_out_features"](%self)
                    %top_block.7 : __torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool = prim::GetAttr[name="top_block"](%self)
                    %in_feature : str = prim::GetAttr[name="in_feature"](%top_block.7)
                    %262 : int = aten::index(%_out_features.1, %in_feature) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:164:47
                    %top_block_in_feature.3 : Tensor = aten::__getitem__(%results.1, %262) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:164:39
                    -> (%top_block_in_feature.3)
                %top_block : __torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool = prim::GetAttr[name="top_block"](%self)
                %271 : Tensor[] = prim::CallMethod[name="forward"](%top_block, %top_block_in_feature) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:165:27
                 = aten::extend(%results.1, %271) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:165:12
                %_out_features.3 : str[] = prim::GetAttr[name="_out_features"](%self)
                %274 : int = aten::len(%_out_features.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:166:15
                %276 : int = aten::len(%results.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:166:42
                %277 : bool = aten::eq(%274, %276) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:166:15
                 = prim::If(%277) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:166:8
                  block0():
                    -> ()
                  block1():
                     = prim::RaiseException(%347) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:166:8
                    -> ()
                %283 : Dict(str, Tensor) = prim::DictConstruct()
                %_out_features : str[] = prim::GetAttr[name="_out_features"](%self)
                %286 : int = aten::len(%_out_features) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:167:15
                %287 : int = aten::len(%results.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:167:15
                %288 : int[] = prim::ListConstruct(%286, %287)
                %289 : int = prim::min(%288) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:167:15
                 = prim::Loop(%289, %290) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:167:15
                  block0(%291 : int):
                    %f.1 : str = aten::__getitem__(%_out_features, %291) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:167:15
                    %res.1 : Tensor = aten::__getitem__(%results.1, %291) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:167:15
                     = aten::_set_item(%283, %f.1, %res.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:167:15
                    -> (%290)
                return (%283)
          
            }
          }
          submodules {
            module __torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                num_levels = 1
                in_feature = p5
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.backbone.fpn.LastLevelMaxPool,
                        %x.1 : Tensor):
                    %13 : Function = prim::Constant[name="_max_pool2d"]()
                    %11 : bool = prim::Constant[value=0]()
                    %3 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:200:44
                    %4 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:200:54
                    %5 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:200:65
                    %6 : int[] = prim::ListConstruct(%3, %3)
                    %7 : int[] = prim::ListConstruct(%4, %4)
                    %8 : int[] = prim::ListConstruct(%5, %5)
                    %10 : int[] = prim::ListConstruct(%3, %3)
                    %14 : Tensor = prim::CallFunction(%13, %x.1, %6, %7, %8, %10, %11, %11) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/fpn.py:200:16
                    %15 : Tensor[] = prim::ListConstruct(%14)
                    return (%15)
              
                }
              }
              submodules {
              }
            }
            module __torch__.detectron2.modeling.backbone.resnet.ResNet {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                num_classes = None
                _out_feature_strides = {stem: 4, res2: 4, res3: 8, res4: 16, res5: 32}
                _out_feature_channels = {stem: 64, res2: 256, res3: 512, res4: 1024, res5: 2048}
                stage_names = (res2, res3, res4, res5)
                _out_features = [res2, res3, res4, res5]
                stem = <__torch__.detectron2.modeling.backbone.resnet.BasicStem object at 0x9b61680>
                stages = <__torch__.torch.nn.modules.container.ModuleList object at 0x12119dd0>
              }
              methods {
                method __padding_constraints_getter {
                  graph(%self : __torch__.detectron2.modeling.backbone.resnet.ResNet):
                    %2 : Dict(str, int) = prim::DictConstruct()
                    return (%2)
              
                }
                method __size_divisibility_getter {
                  graph(%self : __torch__.detectron2.modeling.backbone.resnet.ResNet):
                    %2 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/backbone.py:41:15
                    return (%2)
              
                }
                method forward {
                  graph(%self : __torch__.detectron2.modeling.backbone.resnet.ResNet,
                        %x.1 : Tensor):
                    %19 : str = prim::Constant[value="stem"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:446:11
                    %12 : str = prim::Constant[value="AssertionError: "]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:443:8
                    %8 : str = prim::Constant[value="ResNet takes an input of shape (N, C, H, W). Got {} instead!"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:443:29
                    %5 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:443:26
                    %4 : int = aten::dim(%x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:443:15
                    %6 : bool = aten::eq(%4, %5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:443:15
                     = prim::If(%6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:443:8
                      block0():
                        -> ()
                      block1():
                        %10 : int[] = aten::size(%x.1) # <string>:7:9
                        %11 : str = aten::format(%8, %10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:443:29
                        %13 : str = aten::add(%12, %11) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:443:8
                         = prim::RaiseException(%13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:443:8
                        -> ()
                    %outputs.1 : Dict(str, Tensor) = prim::DictConstruct()
                    %stem : __torch__.detectron2.modeling.backbone.resnet.BasicStem = prim::GetAttr[name="stem"](%self)
                    %x.9 : Tensor = prim::CallMethod[name="forward"](%stem, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:445:12
                    %_out_features.1 : str[] = prim::GetAttr[name="_out_features"](%self)
                    %21 : bool = aten::__contains__(%_out_features.1, %19) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:446:11
                     = prim::If(%21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:446:8
                      block0():
                         = aten::_set_item(%outputs.1, %19, %x.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:447:12
                        -> ()
                      block1():
                        -> ()
                    %stage_names : (str, str, str, str) = prim::GetAttr[name="stage_names"](%self)
                    %name.1 : str, %name.7 : str, %name.13 : str, %name.19 : str = prim::TupleUnpack(%stage_names)
                    %stages : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="stages"](%self)
                    %_0 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="0"](%stages)
                    %_1 : __torch__.torch.nn.modules.container.___torch_mangle_15.Sequential = prim::GetAttr[name="1"](%stages)
                    %_2 : __torch__.torch.nn.modules.container.___torch_mangle_24.Sequential = prim::GetAttr[name="2"](%stages)
                    %_3 : __torch__.torch.nn.modules.container.___torch_mangle_33.Sequential = prim::GetAttr[name="3"](%stages)
                    %x.15 : Tensor = prim::CallMethod[name="forward"](%_0, %x.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:449:16
                    %_out_features.3 : str[] = prim::GetAttr[name="_out_features"](%self)
                    %46 : bool = aten::__contains__(%_out_features.3, %name.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:450:15
                     = prim::If(%46) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:450:12
                      block0():
                         = aten::_set_item(%outputs.1, %name.1, %x.15) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:451:16
                        -> ()
                      block1():
                        -> ()
                    %x.21 : Tensor = prim::CallMethod[name="forward"](%_1, %x.15) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:449:16
                    %_out_features.5 : str[] = prim::GetAttr[name="_out_features"](%self)
                    %57 : bool = aten::__contains__(%_out_features.5, %name.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:450:15
                     = prim::If(%57) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:450:12
                      block0():
                         = aten::_set_item(%outputs.1, %name.7, %x.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:451:16
                        -> ()
                      block1():
                        -> ()
                    %x.27 : Tensor = prim::CallMethod[name="forward"](%_2, %x.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:449:16
                    %_out_features.7 : str[] = prim::GetAttr[name="_out_features"](%self)
                    %68 : bool = aten::__contains__(%_out_features.7, %name.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:450:15
                     = prim::If(%68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:450:12
                      block0():
                         = aten::_set_item(%outputs.1, %name.13, %x.27) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:451:16
                        -> ()
                      block1():
                        -> ()
                    %x.33 : Tensor = prim::CallMethod[name="forward"](%_3, %x.27) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:449:16
                    %_out_features : str[] = prim::GetAttr[name="_out_features"](%self)
                    %79 : bool = aten::__contains__(%_out_features, %name.19) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:450:15
                     = prim::If(%79) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:450:12
                      block0():
                         = aten::_set_item(%outputs.1, %name.19, %x.33) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:451:16
                        -> ()
                      block1():
                        -> ()
                    return (%outputs.1)
              
                }
              }
              submodules {
                module __torch__.detectron2.modeling.backbone.resnet.BasicStem {
                  parameters {
                  }
                  attributes {
                    _is_full_backward_hook = None
                    in_channels = 3
                    out_channels = 64
                    stride = 4
                    conv1 = <__torch__.detectron2.layers.wrappers.Conv2d object at 0x8218ea0>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.modeling.backbone.resnet.BasicStem,
                            %x.1 : Tensor):
                        %18 : Function = prim::Constant[name="_max_pool2d"]()
                        %16 : bool = prim::Constant[value=0]()
                        %8 : int = prim::Constant[value=3]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:358:40
                        %9 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:358:50
                        %10 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:358:61
                        %conv1 : __torch__.detectron2.layers.wrappers.Conv2d = prim::GetAttr[name="conv1"](%self)
                        %x.5 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:356:12
                        %x.9 : Tensor = aten::relu_(%x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:357:12
                        %11 : int[] = prim::ListConstruct(%8, %8)
                        %12 : int[] = prim::ListConstruct(%9, %9)
                        %13 : int[] = prim::ListConstruct(%10, %10)
                        %15 : int[] = prim::ListConstruct(%10, %10)
                        %x.13 : Tensor = prim::CallFunction(%18, %x.9, %11, %12, %13, %15, %16, %16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:358:12
                        return (%x.13)
                  
                    }
                  }
                  submodules {
                    module __torch__.detectron2.layers.wrappers.Conv2d {
                      parameters {
                        weight = ...
                      }
                      attributes {
                        weight = ...
                        bias = None
                        training = False
                        _is_full_backward_hook = None
                        transposed = False
                        _reversed_padding_repeated_twice = [3, 3, 3, 3]
                        activation = None
                        norm = <__torch__.torch.nn.modules.batchnorm.BatchNorm2d object at 0x1212fba0>
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.wrappers.Conv2d,
                                %x.1 : Tensor):
                            %14 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:66
                            %11 : int = prim::Constant[value=3]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                            %8 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                            %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                            %18 : int[] = prim::ListConstruct(%8, %8)
                            %19 : int[] = prim::ListConstruct(%11, %11)
                            %20 : int[] = prim::ListConstruct(%14, %14)
                            %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                            %norm : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                            %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                            return (%x.9)
                      
                        }
                      }
                      submodules {
                        module __torch__.torch.nn.modules.batchnorm.BatchNorm2d {
                          parameters {
                            weight = ...
                            bias = ...
                          }
                          attributes {
                            weight = ...
                            bias = ...
                            running_mean = ...
                            running_var = ...
                            num_batches_tracked = ...
                            training = False
                            _is_full_backward_hook = None
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                    %input.1 : Tensor):
                                %69 : Function = prim::Constant[name="batch_norm"]()
                                %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                %97 : float = prim::Constant[value=0.10000000000000001]()
                                %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                %training.1 : bool = prim::GetAttr[name="training"](%self)
                                 = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                  block0():
                                    %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                    %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                     = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                    -> ()
                                  block1():
                                    -> ()
                                %training.3 : bool = prim::GetAttr[name="training"](%self)
                                %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                  block0():
                                    -> (%bn_training.1)
                                  block1():
                                    -> (%40)
                                %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                return (%70)
                          
                            }
                            method _check_input_dim {
                              graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                    %input.1 : Tensor):
                                %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                 = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                  block0():
                                    %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                    %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                     = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                    -> ()
                                  block1():
                                    -> ()
                                return (%12)
                          
                            }
                          }
                          submodules {
                          }
                        }
                      }
                    }
                  }
                }
                module __torch__.torch.nn.modules.container.ModuleList {
                  parameters {
                  }
                  attributes {
                    _is_full_backward_hook = None
                    0 = <__torch__.torch.nn.modules.container.Sequential object at 0x8222d70>
                    1 = <__torch__.torch.nn.modules.container.___torch_mangle_15.Sequential object at 0x119646b0>
                    2 = <__torch__.torch.nn.modules.container.___torch_mangle_24.Sequential object at 0x11958fb0>
                    3 = <__torch__.torch.nn.modules.container.___torch_mangle_33.Sequential object at 0xde72c60>
                  }
                  methods {
                    method __len__ {
                      graph(%self : __torch__.torch.nn.modules.container.ModuleList):
                        %1 : int = prim::Constant[value=4]() # <string>:2:10
                        return (%1)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.container.Sequential {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.modeling.backbone.resnet.BottleneckBlock object at 0x8221e10>
                        1 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_5.BottleneckBlock object at 0x5f4d740>
                        2 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_5.BottleneckBlock object at 0xaa75950>
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.container.Sequential,
                                %input.1 : Tensor):
                            %_0 : __torch__.detectron2.modeling.backbone.resnet.BottleneckBlock = prim::GetAttr[name="0"](%self)
                            %_1 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_5.BottleneckBlock = prim::GetAttr[name="1"](%self)
                            %_2 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_5.BottleneckBlock = prim::GetAttr[name="2"](%self)
                            %input.5 : Tensor = prim::CallMethod[name="forward"](%_0, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            %input.9 : Tensor = prim::CallMethod[name="forward"](%_1, %input.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            %input.13 : Tensor = prim::CallMethod[name="forward"](%_2, %input.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            return (%input.13)
                      
                        }
                        method __len__ {
                          graph(%self : __torch__.torch.nn.modules.container.Sequential):
                            %1 : int = prim::Constant[value=3]() # <string>:2:10
                            return (%1)
                      
                        }
                      }
                      submodules {
                        module __torch__.detectron2.modeling.backbone.resnet.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 64
                            out_channels = 256
                            stride = 1
                            shortcut = <__torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d object at 0xaa74ba0>
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d object at 0x821a240>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d object at 0x1212f540>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d object at 0x121249a0>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.BottleneckBlock,
                                    %x.1 : Tensor):
                                %23 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %shortcut.3 : __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d = prim::GetAttr[name="shortcut"](%self)
                                %shortcut.5 : Tensor = prim::CallMethod[name="forward"](%shortcut.3, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:204:23
                                %out.21 : Tensor = aten::add_(%out.17, %shortcut.5, %23) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x82302f0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.BatchNorm2d object at 0x5f4d660>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_2.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.BatchNorm2d object at 0x5f513d0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x5f4d6e0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_5.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 256
                            out_channels = 256
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_4.Conv2d object at 0x121294b0>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d object at 0x8223b80>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d object at 0x822f9c0>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_5.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_4.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_4.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.BatchNorm2d object at 0xb4c85b0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_4.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.BatchNorm2d object at 0xaa76980>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x9b66830>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_5.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 256
                            out_channels = 256
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_4.Conv2d object at 0x12128170>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d object at 0x1212dcc0>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d object at 0x5f4b210>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_5.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_4.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_4.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.BatchNorm2d object at 0x5f50c60>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_4.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.BatchNorm2d object at 0xaa74750>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_3.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x8212090>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_1.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_15.Sequential {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_12.BottleneckBlock object at 0xa9c4490>
                        1 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_14.BottleneckBlock object at 0xa9cbe90>
                        2 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_14.BottleneckBlock object at 0x11baa3b0>
                        3 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_14.BottleneckBlock object at 0x11ba5430>
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_15.Sequential,
                                %input.1 : Tensor):
                            %_0 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_12.BottleneckBlock = prim::GetAttr[name="0"](%self)
                            %_1 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_14.BottleneckBlock = prim::GetAttr[name="1"](%self)
                            %_2 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_14.BottleneckBlock = prim::GetAttr[name="2"](%self)
                            %_3 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_14.BottleneckBlock = prim::GetAttr[name="3"](%self)
                            %input.5 : Tensor = prim::CallMethod[name="forward"](%_0, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            %input.9 : Tensor = prim::CallMethod[name="forward"](%_1, %input.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            %input.13 : Tensor = prim::CallMethod[name="forward"](%_2, %input.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            %input.17 : Tensor = prim::CallMethod[name="forward"](%_3, %input.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            return (%input.17)
                      
                        }
                        method __len__ {
                          graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_15.Sequential):
                            %1 : int = prim::Constant[value=4]() # <string>:2:10
                            return (%1)
                      
                        }
                      }
                      submodules {
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_12.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 256
                            out_channels = 512
                            stride = 2
                            shortcut = <__torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d object at 0x5f50350>
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_9.Conv2d object at 0xa9c7910>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d object at 0x12116430>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d object at 0xa9d6f50>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_12.BottleneckBlock,
                                    %x.1 : Tensor):
                                %23 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_9.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %shortcut.3 : __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d = prim::GetAttr[name="shortcut"](%self)
                                %shortcut.5 : Tensor = prim::CallMethod[name="forward"](%shortcut.3, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:204:23
                                %out.21 : Tensor = aten::add_(%out.17, %shortcut.5, %23) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d object at 0xb4c8a50>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_7.Conv2d,
                                        %x.1 : Tensor):
                                    %14 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:66
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%14, %14)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_9.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d object at 0x821bc50>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_9.Conv2d,
                                        %x.1 : Tensor):
                                    %14 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:66
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%14, %14)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d object at 0xa9d69f0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d object at 0x1213fe90>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_14.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 512
                            out_channels = 512
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d object at 0xa9d0940>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d object at 0xa9dc130>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d object at 0x821f9a0>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_14.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d object at 0x11957350>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d object at 0x11b97ac0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d object at 0x11ba78d0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_14.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 512
                            out_channels = 512
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d object at 0x822f600>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d object at 0x119538e0>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d object at 0xb4c2200>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_14.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d object at 0x5f4b080>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d object at 0x11ba4540>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d object at 0x5f4daa0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_14.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 512
                            out_channels = 512
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d object at 0xa9cae20>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d object at 0xa9d5800>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d object at 0x11ba7f60>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_14.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d object at 0x11b9ab00>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_13.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d object at 0x11bb2c70>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_10.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_8.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d object at 0x8233510>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_11.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_24.Sequential {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_21.BottleneckBlock object at 0x1211c910>
                        1 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock object at 0x60adc40>
                        2 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock object at 0x60c1b10>
                        3 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock object at 0x60bdb00>
                        4 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock object at 0xde65b90>
                        5 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock object at 0x60ac7a0>
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_24.Sequential,
                                %input.1 : Tensor):
                            %_0 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_21.BottleneckBlock = prim::GetAttr[name="0"](%self)
                            %_1 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock = prim::GetAttr[name="1"](%self)
                            %_2 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock = prim::GetAttr[name="2"](%self)
                            %_3 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock = prim::GetAttr[name="3"](%self)
                            %_4 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock = prim::GetAttr[name="4"](%self)
                            %_5 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock = prim::GetAttr[name="5"](%self)
                            %input.5 : Tensor = prim::CallMethod[name="forward"](%_0, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            %input.9 : Tensor = prim::CallMethod[name="forward"](%_1, %input.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            %input.13 : Tensor = prim::CallMethod[name="forward"](%_2, %input.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            %input.17 : Tensor = prim::CallMethod[name="forward"](%_3, %input.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            %input.21 : Tensor = prim::CallMethod[name="forward"](%_4, %input.17) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            %input.25 : Tensor = prim::CallMethod[name="forward"](%_5, %input.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            return (%input.25)
                      
                        }
                        method __len__ {
                          graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_24.Sequential):
                            %1 : int = prim::Constant[value=6]() # <string>:2:10
                            return (%1)
                      
                        }
                      }
                      submodules {
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_21.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 512
                            out_channels = 1024
                            stride = 2
                            shortcut = <__torch__.detectron2.layers.wrappers.___torch_mangle_17.Conv2d object at 0xa9cc8a0>
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d object at 0x121327d0>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d object at 0x60c0130>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d object at 0x7ab9e80>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_21.BottleneckBlock,
                                    %x.1 : Tensor):
                                %23 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %shortcut.3 : __torch__.detectron2.layers.wrappers.___torch_mangle_17.Conv2d = prim::GetAttr[name="shortcut"](%self)
                                %shortcut.5 : Tensor = prim::CallMethod[name="forward"](%shortcut.3, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:204:23
                                %out.21 : Tensor = aten::add_(%out.17, %shortcut.5, %23) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_17.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d object at 0x11baf370>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_17.Conv2d,
                                        %x.1 : Tensor):
                                    %14 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:66
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%14, %14)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x11bb2bf0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_18.Conv2d,
                                        %x.1 : Tensor):
                                    %14 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:66
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%14, %14)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x11ba6920>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d object at 0x60b20d0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 1024
                            out_channels = 1024
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d object at 0x11b9b120>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d object at 0x60b8550>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d object at 0x60ad5c0>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x11b98db0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x60acce0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d object at 0xde61440>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 1024
                            out_channels = 1024
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d object at 0x60c4550>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d object at 0xde66bb0>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d object at 0xa9d04e0>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x11babc70>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0xde64540>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d object at 0xde61d00>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 1024
                            out_channels = 1024
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d object at 0x60c0080>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d object at 0x60b4380>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d object at 0x60c1900>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x60aee80>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0xa9dc290>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d object at 0x60c45d0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 1024
                            out_channels = 1024
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d object at 0x60c4740>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d object at 0xde6c0f0>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d object at 0xde65140>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x11b9a5e0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0xde70220>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d object at 0x11ba6340>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 1024
                            out_channels = 1024
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d object at 0xde6d850>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d object at 0x60bb020>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d object at 0xde69440>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_23.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x60aee00>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x60bb1c0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d object at 0xde73cd0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_20.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_16.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                    module __torch__.torch.nn.modules.container.___torch_mangle_33.Sequential {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        0 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_30.BottleneckBlock object at 0x11bb46f0>
                        1 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_32.BottleneckBlock object at 0x60c81d0>
                        2 = <__torch__.detectron2.modeling.backbone.resnet.___torch_mangle_32.BottleneckBlock object at 0xa9ceaf0>
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_33.Sequential,
                                %input.1 : Tensor):
                            %_0 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_30.BottleneckBlock = prim::GetAttr[name="0"](%self)
                            %_1 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_32.BottleneckBlock = prim::GetAttr[name="1"](%self)
                            %_2 : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_32.BottleneckBlock = prim::GetAttr[name="2"](%self)
                            %input.5 : Tensor = prim::CallMethod[name="forward"](%_0, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            %input.9 : Tensor = prim::CallMethod[name="forward"](%_1, %input.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            %input.13 : Tensor = prim::CallMethod[name="forward"](%_2, %input.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py:141:20
                            return (%input.13)
                      
                        }
                        method __len__ {
                          graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_33.Sequential):
                            %1 : int = prim::Constant[value=3]() # <string>:2:10
                            return (%1)
                      
                        }
                      }
                      submodules {
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_30.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 1024
                            out_channels = 2048
                            stride = 2
                            shortcut = <__torch__.detectron2.layers.wrappers.___torch_mangle_26.Conv2d object at 0x82244c0>
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_27.Conv2d object at 0x60b84f0>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_28.Conv2d object at 0xaacb2f0>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d object at 0xaac95a0>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_30.BottleneckBlock,
                                    %x.1 : Tensor):
                                %23 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_27.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_28.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %shortcut.3 : __torch__.detectron2.layers.wrappers.___torch_mangle_26.Conv2d = prim::GetAttr[name="shortcut"](%self)
                                %shortcut.5 : Tensor = prim::CallMethod[name="forward"](%shortcut.3, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:204:23
                                %out.21 : Tensor = aten::add_(%out.17, %shortcut.5, %23) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_26.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d object at 0xa9c79a0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_26.Conv2d,
                                        %x.1 : Tensor):
                                    %14 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:66
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%14, %14)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_27.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d object at 0xde83cc0>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_27.Conv2d,
                                        %x.1 : Tensor):
                                    %14 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:66
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%14, %14)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %14) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_28.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d object at 0xaac9520>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_28.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d object at 0xaad0b50>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_32.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 2048
                            out_channels = 2048
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_31.Conv2d object at 0xde6ce60>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_28.Conv2d object at 0xde76020>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d object at 0xde7d220>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_32.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_31.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_28.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_31.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d object at 0xde72250>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_31.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_28.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d object at 0xde74480>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_28.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d object at 0xde7b030>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                        module __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_32.BottleneckBlock {
                          parameters {
                          }
                          attributes {
                            _is_full_backward_hook = None
                            in_channels = 2048
                            out_channels = 2048
                            stride = 1
                            shortcut = None
                            conv1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_31.Conv2d object at 0xde7cbc0>
                            conv2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_28.Conv2d object at 0xde79820>
                            conv3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d object at 0xaae7a30>
                          }
                          methods {
                            method forward {
                              graph(%self : __torch__.detectron2.modeling.backbone.resnet.___torch_mangle_32.BottleneckBlock,
                                    %x.1 : Tensor):
                                %21 : int = prim::Constant[value=1]()
                                %conv1 : __torch__.detectron2.layers.wrappers.___torch_mangle_31.Conv2d = prim::GetAttr[name="conv1"](%self)
                                %out.1 : Tensor = prim::CallMethod[name="forward"](%conv1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:195:14
                                %out.5 : Tensor = aten::relu_(%out.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:196:14
                                %conv2 : __torch__.detectron2.layers.wrappers.___torch_mangle_28.Conv2d = prim::GetAttr[name="conv2"](%self)
                                %out.9 : Tensor = prim::CallMethod[name="forward"](%conv2, %out.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:198:14
                                %out.13 : Tensor = aten::relu_(%out.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:199:14
                                %conv3 : __torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d = prim::GetAttr[name="conv3"](%self)
                                %out.17 : Tensor = prim::CallMethod[name="forward"](%conv3, %out.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:201:14
                                %out.21 : Tensor = aten::add_(%out.17, %x.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:208:8
                                %out.25 : Tensor = aten::relu_(%out.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/backbone/resnet.py:209:14
                                return (%out.25)
                          
                            }
                          }
                          submodules {
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_31.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d object at 0xde7db30>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_31.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_28.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [1, 1, 1, 1]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d object at 0xaad2a90>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_28.Conv2d,
                                        %x.1 : Tensor):
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%8, %8)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_6.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                            module __torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d {
                              parameters {
                                weight = ...
                              }
                              attributes {
                                weight = ...
                                bias = None
                                training = False
                                _is_full_backward_hook = None
                                transposed = False
                                _reversed_padding_repeated_twice = [0, 0, 0, 0]
                                activation = None
                                norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d object at 0xde7f550>
                              }
                              methods {
                                method forward {
                                  graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_29.Conv2d,
                                        %x.1 : Tensor):
                                    %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                                    %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                                    %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                    %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                                    %18 : int[] = prim::ListConstruct(%8, %8)
                                    %19 : int[] = prim::ListConstruct(%11, %11)
                                    %20 : int[] = prim::ListConstruct(%8, %8)
                                    %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                                    %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                                    %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                                    return (%x.9)
                              
                                }
                              }
                              submodules {
                                module __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d {
                                  parameters {
                                    weight = ...
                                    bias = ...
                                  }
                                  attributes {
                                    weight = ...
                                    bias = ...
                                    running_mean = ...
                                    running_var = ...
                                    num_batches_tracked = ...
                                    training = False
                                    _is_full_backward_hook = None
                                  }
                                  methods {
                                    method forward {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %69 : Function = prim::Constant[name="batch_norm"]()
                                        %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                                        %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                                        %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                                        %97 : float = prim::Constant[value=0.10000000000000001]()
                                        %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                                        %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                                        %training.1 : bool = prim::GetAttr[name="training"](%self)
                                         = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                                          block0():
                                            %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                            %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                             = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                            -> ()
                                          block1():
                                            -> ()
                                        %training.3 : bool = prim::GetAttr[name="training"](%self)
                                        %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                                          block0():
                                            -> (%bn_training.1)
                                          block1():
                                            -> (%40)
                                        %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                                        %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                                        %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                                        return (%70)
                                  
                                    }
                                    method _check_input_dim {
                                      graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_25.BatchNorm2d,
                                            %input.1 : Tensor):
                                        %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                                        %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                        %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                                        %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                        %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                                         = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                                          block0():
                                            %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                            %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                             = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                            -> ()
                                          block1():
                                            -> ()
                                        return (%12)
                                  
                                    }
                                  }
                                  submodules {
                                  }
                                }
                              }
                            }
                          }
                        }
                      }
                    }
                  }
                }
              }
            }
            module __torch__.torch.nn.modules.container.___torch_mangle_37.ModuleList {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                0 = <__torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d object at 0x11b9ecc0>
                1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d object at 0x60c1990>
                2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_35.Conv2d object at 0xaaeec70>
                3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d object at 0xaaea900>
              }
              methods {
                method __len__ {
                  graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_37.ModuleList):
                    %1 : int = prim::Constant[value=4]() # <string>:2:10
                    return (%1)
              
                }
              }
              submodules {
                module __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d {
                  parameters {
                    weight = ...
                  }
                  attributes {
                    weight = ...
                    bias = None
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                    activation = None
                    norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0xaae5360>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_34.Conv2d,
                            %x.1 : Tensor):
                        %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%11, %11)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                      parameters {
                        weight = ...
                        bias = ...
                      }
                      attributes {
                        weight = ...
                        bias = ...
                        running_mean = ...
                        running_var = ...
                        num_batches_tracked = ...
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %69 : Function = prim::Constant[name="batch_norm"]()
                            %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                            %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                            %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                            %97 : float = prim::Constant[value=0.10000000000000001]()
                            %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                            %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                            %training.1 : bool = prim::GetAttr[name="training"](%self)
                             = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                              block0():
                                %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                 = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                -> ()
                              block1():
                                -> ()
                            %training.3 : bool = prim::GetAttr[name="training"](%self)
                            %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                              block0():
                                -> (%bn_training.1)
                              block1():
                                -> (%40)
                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                            %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                            return (%70)
                      
                        }
                        method _check_input_dim {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                            %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                            %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                            %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                            %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                             = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                              block0():
                                %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                 = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                -> ()
                              block1():
                                -> ()
                            return (%12)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d {
                  parameters {
                    weight = ...
                  }
                  attributes {
                    weight = ...
                    bias = None
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                    activation = None
                    norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x11b9b960>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_22.Conv2d,
                            %x.1 : Tensor):
                        %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%11, %11)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                      parameters {
                        weight = ...
                        bias = ...
                      }
                      attributes {
                        weight = ...
                        bias = ...
                        running_mean = ...
                        running_var = ...
                        num_batches_tracked = ...
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %69 : Function = prim::Constant[name="batch_norm"]()
                            %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                            %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                            %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                            %97 : float = prim::Constant[value=0.10000000000000001]()
                            %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                            %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                            %training.1 : bool = prim::GetAttr[name="training"](%self)
                             = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                              block0():
                                %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                 = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                -> ()
                              block1():
                                -> ()
                            %training.3 : bool = prim::GetAttr[name="training"](%self)
                            %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                              block0():
                                -> (%bn_training.1)
                              block1():
                                -> (%40)
                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                            %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                            return (%70)
                      
                        }
                        method _check_input_dim {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                            %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                            %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                            %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                            %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                             = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                              block0():
                                %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                 = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                -> ()
                              block1():
                                -> ()
                            return (%12)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_35.Conv2d {
                  parameters {
                    weight = ...
                  }
                  attributes {
                    weight = ...
                    bias = None
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                    activation = None
                    norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0xde62ef0>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_35.Conv2d,
                            %x.1 : Tensor):
                        %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%11, %11)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                      parameters {
                        weight = ...
                        bias = ...
                      }
                      attributes {
                        weight = ...
                        bias = ...
                        running_mean = ...
                        running_var = ...
                        num_batches_tracked = ...
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %69 : Function = prim::Constant[name="batch_norm"]()
                            %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                            %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                            %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                            %97 : float = prim::Constant[value=0.10000000000000001]()
                            %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                            %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                            %training.1 : bool = prim::GetAttr[name="training"](%self)
                             = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                              block0():
                                %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                 = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                -> ()
                              block1():
                                -> ()
                            %training.3 : bool = prim::GetAttr[name="training"](%self)
                            %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                              block0():
                                -> (%bn_training.1)
                              block1():
                                -> (%40)
                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                            %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                            return (%70)
                      
                        }
                        method _check_input_dim {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                            %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                            %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                            %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                            %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                             = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                              block0():
                                %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                 = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                -> ()
                              block1():
                                -> ()
                            return (%12)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d {
                  parameters {
                    weight = ...
                  }
                  attributes {
                    weight = ...
                    bias = None
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                    activation = None
                    norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0xde60c30>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_36.Conv2d,
                            %x.1 : Tensor):
                        %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%11, %11)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                      parameters {
                        weight = ...
                        bias = ...
                      }
                      attributes {
                        weight = ...
                        bias = ...
                        running_mean = ...
                        running_var = ...
                        num_batches_tracked = ...
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %69 : Function = prim::Constant[name="batch_norm"]()
                            %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                            %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                            %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                            %97 : float = prim::Constant[value=0.10000000000000001]()
                            %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                            %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                            %training.1 : bool = prim::GetAttr[name="training"](%self)
                             = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                              block0():
                                %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                 = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                -> ()
                              block1():
                                -> ()
                            %training.3 : bool = prim::GetAttr[name="training"](%self)
                            %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                              block0():
                                -> (%bn_training.1)
                              block1():
                                -> (%40)
                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                            %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                            return (%70)
                      
                        }
                        method _check_input_dim {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                            %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                            %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                            %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                            %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                             = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                              block0():
                                %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                 = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                -> ()
                              block1():
                                -> ()
                            return (%12)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
              }
            }
            module __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                0 = <__torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d object at 0xaae7d70>
                1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d object at 0xaacf9c0>
                2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d object at 0xaaf09a0>
                3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d object at 0x9b602f0>
              }
              methods {
                method __len__ {
                  graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_38.ModuleList):
                    %1 : int = prim::Constant[value=4]() # <string>:2:10
                    return (%1)
              
                }
              }
              submodules {
                module __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d {
                  parameters {
                    weight = ...
                  }
                  attributes {
                    weight = ...
                    bias = None
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    activation = None
                    norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0x822b5f0>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                      parameters {
                        weight = ...
                        bias = ...
                      }
                      attributes {
                        weight = ...
                        bias = ...
                        running_mean = ...
                        running_var = ...
                        num_batches_tracked = ...
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %69 : Function = prim::Constant[name="batch_norm"]()
                            %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                            %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                            %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                            %97 : float = prim::Constant[value=0.10000000000000001]()
                            %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                            %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                            %training.1 : bool = prim::GetAttr[name="training"](%self)
                             = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                              block0():
                                %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                 = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                -> ()
                              block1():
                                -> ()
                            %training.3 : bool = prim::GetAttr[name="training"](%self)
                            %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                              block0():
                                -> (%bn_training.1)
                              block1():
                                -> (%40)
                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                            %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                            return (%70)
                      
                        }
                        method _check_input_dim {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                            %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                            %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                            %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                            %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                             = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                              block0():
                                %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                 = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                -> ()
                              block1():
                                -> ()
                            return (%12)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d {
                  parameters {
                    weight = ...
                  }
                  attributes {
                    weight = ...
                    bias = None
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    activation = None
                    norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0xaae9b50>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                      parameters {
                        weight = ...
                        bias = ...
                      }
                      attributes {
                        weight = ...
                        bias = ...
                        running_mean = ...
                        running_var = ...
                        num_batches_tracked = ...
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %69 : Function = prim::Constant[name="batch_norm"]()
                            %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                            %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                            %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                            %97 : float = prim::Constant[value=0.10000000000000001]()
                            %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                            %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                            %training.1 : bool = prim::GetAttr[name="training"](%self)
                             = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                              block0():
                                %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                 = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                -> ()
                              block1():
                                -> ()
                            %training.3 : bool = prim::GetAttr[name="training"](%self)
                            %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                              block0():
                                -> (%bn_training.1)
                              block1():
                                -> (%40)
                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                            %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                            return (%70)
                      
                        }
                        method _check_input_dim {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                            %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                            %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                            %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                            %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                             = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                              block0():
                                %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                 = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                -> ()
                              block1():
                                -> ()
                            return (%12)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d {
                  parameters {
                    weight = ...
                  }
                  attributes {
                    weight = ...
                    bias = None
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    activation = None
                    norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0xaad2c20>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                      parameters {
                        weight = ...
                        bias = ...
                      }
                      attributes {
                        weight = ...
                        bias = ...
                        running_mean = ...
                        running_var = ...
                        num_batches_tracked = ...
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %69 : Function = prim::Constant[name="batch_norm"]()
                            %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                            %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                            %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                            %97 : float = prim::Constant[value=0.10000000000000001]()
                            %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                            %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                            %training.1 : bool = prim::GetAttr[name="training"](%self)
                             = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                              block0():
                                %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                 = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                -> ()
                              block1():
                                -> ()
                            %training.3 : bool = prim::GetAttr[name="training"](%self)
                            %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                              block0():
                                -> (%bn_training.1)
                              block1():
                                -> (%40)
                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                            %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                            return (%70)
                      
                        }
                        method _check_input_dim {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                            %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                            %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                            %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                            %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                             = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                              block0():
                                %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                 = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                -> ()
                              block1():
                                -> ()
                            return (%12)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d {
                  parameters {
                    weight = ...
                  }
                  attributes {
                    weight = ...
                    bias = None
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    activation = None
                    norm = <__torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d object at 0xaaf3370>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_19.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %norm : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d = prim::GetAttr[name="norm"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%norm, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:115:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d {
                      parameters {
                        weight = ...
                        bias = ...
                      }
                      attributes {
                        weight = ...
                        bias = ...
                        running_mean = ...
                        running_var = ...
                        num_batches_tracked = ...
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %69 : Function = prim::Constant[name="batch_norm"]()
                            %68 : float = prim::Constant[value=1.0000000000000001e-05]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:179:12
                            %40 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:161:27
                            %bn_training.1 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:159:26
                            %97 : float = prim::Constant[value=0.10000000000000001]()
                            %18 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:70
                            %3 : NoneType = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:135:8
                            %training.1 : bool = prim::GetAttr[name="training"](%self)
                             = prim::If(%training.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:145:11
                              block0():
                                %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
                                %91 : Tensor = aten::add(%num_batches_tracked.7, %18, %18) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:148:43
                                 = prim::SetAttr[name="num_batches_tracked"](%self, %91)
                                -> ()
                              block1():
                                -> ()
                            %training.3 : bool = prim::GetAttr[name="training"](%self)
                            %bn_training : bool = prim::If(%training.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:158:8
                              block0():
                                -> (%bn_training.1)
                              block1():
                                -> (%40)
                            %running_mean : Tensor = prim::GetAttr[name="running_mean"](%self)
                            %running_var : Tensor = prim::GetAttr[name="running_var"](%self)
                            %weight : Tensor = prim::GetAttr[name="weight"](%self)
                            %bias : Tensor = prim::GetAttr[name="bias"](%self)
                            %70 : Tensor = prim::CallFunction(%69, %input.1, %running_mean, %running_var, %weight, %bias, %bn_training, %97, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:168:15
                            return (%70)
                      
                        }
                        method _check_input_dim {
                          graph(%self : __torch__.torch.nn.modules.batchnorm.___torch_mangle_0.BatchNorm2d,
                                %input.1 : Tensor):
                            %12 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:406:4
                            %7 : str = prim::Constant[value="expected 4D input (got {}D input)"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                            %4 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:26
                            %3 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                            %5 : bool = aten::ne(%3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:11
                             = prim::If(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:407:8
                              block0():
                                %9 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:72
                                %10 : str = aten::format(%7, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:29
                                 = prim::RaiseException(%10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:408:12
                                -> ()
                              block1():
                                -> ()
                            return (%12)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
              }
            }
          }
        }
        module __torch__.detectron2.modeling.proposal_generator.rpn.RPN {
          parameters {
          }
          attributes {
            _is_full_backward_hook = None
            in_features = [p2, p3, p4, p5, p6]
            anchor_matcher = <__torch__.detectron2.modeling.matcher.Matcher object at 0x60ab7d0>
            box2box_transform = <__torch__.detectron2.modeling.box_regression.Box2BoxTransform object at 0xde71040>
            batch_size_per_image = 256
            positive_fraction = 0.5
            pre_nms_topk = {True: 2000, False: 1000}
            post_nms_topk = {True: 1000, False: 1000}
            nms_thresh = 0.69999999999999996
            min_box_size = 0.
            anchor_boundary_thresh = -1.
            loss_weight = {loss_rpn_cls: 1., loss_rpn_loc: 1.}
            box_reg_loss_type = smooth_l1
            smooth_l1_beta = 0.
            rpn_head = <__torch__.detectron2.modeling.proposal_generator.rpn.StandardRPNHead object at 0x63e2d30>
            anchor_generator = <__torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator object at 0x84d11b0>
          }
          methods {
            method forward {
              graph(%self : __torch__.detectron2.modeling.proposal_generator.rpn.RPN,
                    %images.1 : __torch__.detectron2.structures.image_list.ImageList,
                    %features.1 : Dict(str, Tensor),
                    %gt_instances : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]?):
                %56 : int = prim::Constant[value=-2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:463:74
                %36 : int = prim::Constant[value=-1]()
                %8 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:451:19
                %30 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:458:26
                %31 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:458:29
                %32 : int = prim::Constant[value=3]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:458:32
                %33 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:458:35
                %65 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:464:27
                %features.5 : Tensor[] = prim::ListConstruct()
                %in_features : str[] = prim::GetAttr[name="in_features"](%self)
                %7 : int = aten::len(%in_features) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:451:19
                 = prim::Loop(%7, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:451:19
                  block0(%9 : int):
                    %f.1 : str = aten::__getitem__(%in_features, %9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:451:19
                    %13 : Tensor = aten::__getitem__(%features.1, %f.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:451:20
                    %14 : Tensor[] = aten::append(%features.5, %13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:451:19
                    -> (%8)
                %anchor_generator.1 : __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator = prim::GetAttr[name="anchor_generator"](%self)
                %anchors.1 : __torch__.detectron2.structures.boxes.Boxes[] = prim::CallMethod[name="forward"](%anchor_generator.1, %features.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:452:18
                %rpn_head : __torch__.detectron2.modeling.proposal_generator.rpn.StandardRPNHead = prim::GetAttr[name="rpn_head"](%self)
                %20 : (Tensor[], Tensor[]) = prim::CallMethod[name="forward"](%rpn_head, %features.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:454:53
                %pred_objectness_logits.1 : Tensor[], %pred_anchor_deltas.1 : Tensor[] = prim::TupleUnpack(%20)
                %pred_objectness_logits.5 : Tensor[] = prim::ListConstruct()
                %25 : int = aten::len(%pred_objectness_logits.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:456:33
                 = prim::Loop(%25, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:456:33
                  block0(%27 : int):
                    %score.1 : Tensor = aten::__getitem__(%pred_objectness_logits.1, %27) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:456:33
                    %34 : int[] = prim::ListConstruct(%30, %31, %32, %33)
                    %35 : Tensor = aten::permute(%score.1, %34) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:458:12
                    %37 : Tensor = aten::flatten(%35, %33, %36) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:458:12
                    %38 : Tensor[] = aten::append(%pred_objectness_logits.5, %37) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:456:33
                    -> (%8)
                %pred_anchor_deltas.5 : Tensor[] = prim::ListConstruct()
                %41 : int = aten::len(%pred_anchor_deltas.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:461:29
                 = prim::Loop(%41, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:461:29
                  block0(%43 : int):
                    %x.1 : Tensor = aten::__getitem__(%pred_anchor_deltas.1, %43) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:461:29
                    %47 : int[] = aten::size(%x.1) # <string>:7:9
                    %48 : int = aten::__getitem__(%47, %30) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:463:19
                    %54 : int[] = aten::size(%x.1) # <string>:7:9
                    %57 : int = aten::__getitem__(%54, %56) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:463:66
                    %59 : int[] = aten::size(%x.1) # <string>:7:9
                    %62 : int = aten::__getitem__(%59, %36) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:463:79
                    %63 : int[] = prim::ListConstruct(%48, %36, %65, %57, %62)
                    %64 : Tensor = aten::view(%x.1, %63) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:463:12
                    %66 : int[] = prim::ListConstruct(%30, %32, %65, %33, %31)
                    %67 : Tensor = aten::permute(%64, %66) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:463:12
                    %70 : Tensor = aten::flatten(%67, %33, %56) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:463:12
                    %71 : Tensor[] = aten::append(%pred_anchor_deltas.5, %70) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:461:29
                    -> (%8)
                %losses.1 : Dict(str, Tensor) = prim::DictConstruct()
                %image_sizes : (int, int)[] = prim::GetAttr[name="image_sizes"](%images.1)
                %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="predict_proposals"](%self, %anchors.1, %pred_objectness_logits.5, %pred_anchor_deltas.5, %image_sizes) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:477:20
                %83 : (__torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], Dict(str, Tensor)) = prim::TupleConstruct(%proposals.1, %losses.1)
                return (%83)
          
            }
            method predict_proposals {
              graph(%self : __torch__.detectron2.modeling.proposal_generator.rpn.RPN,
                    %anchors.1 : __torch__.detectron2.structures.boxes.Boxes[],
                    %pred_objectness_logits.1 : Tensor[],
                    %pred_anchor_deltas.1 : Tensor[],
                    %image_sizes.1 : (int, int)[]):
                %24 : Function = prim::Constant[name="find_top_rpn_proposals"]()
                %17 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:508:34
                %6 : __torch__.torch.autograd.grad_mode.no_grad = prim::CreateObject()
                %7 : NoneType = prim::CallMethod[name="__init__"](%6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:501:13
                %8 : NoneType = prim::Enter(%6)
                %pred_proposals.1 : Tensor[] = prim::CallMethod[name="_decode_proposals"](%self, %anchors.1, %pred_anchor_deltas.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:502:29
                %nms_thresh : float = prim::GetAttr[name="nms_thresh"](%self)
                %pre_nms_topk : Dict(bool, int) = prim::GetAttr[name="pre_nms_topk"](%self)
                %18 : int = aten::__getitem__(%pre_nms_topk, %17) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:508:16
                %post_nms_topk : Dict(bool, int) = prim::GetAttr[name="post_nms_topk"](%self)
                %21 : int = aten::__getitem__(%post_nms_topk, %17) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:509:16
                %min_box_size : float = prim::GetAttr[name="min_box_size"](%self)
                %25 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallFunction(%24, %pred_proposals.1, %pred_objectness_logits.1, %image_sizes.1, %nms_thresh, %18, %21, %min_box_size, %17) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:503:19
                %26 : Tensor = prim::Exit(%6)
                return (%25)
          
            }
            method _decode_proposals {
              graph(%self : __torch__.detectron2.modeling.proposal_generator.rpn.RPN,
                    %anchors.1 : __torch__.detectron2.structures.boxes.Boxes[],
                    %pred_anchor_deltas.1 : Tensor[]):
                %40 : bool = prim::Constant[value=0]()
                %27 : int = prim::Constant[value=-1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:527:64
                %16 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:525:8
                %5 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:522:31
                %23 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:526:38
                %6 : Tensor = aten::__getitem__(%pred_anchor_deltas.1, %5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:522:12
                %7 : int[] = aten::size(%6) # <string>:7:9
                %N.1 : int = aten::__getitem__(%7, %5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:522:12
                %proposals.1 : Tensor[] = prim::ListConstruct()
                %12 : int = aten::len(%anchors.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:525:8
                %13 : int = aten::len(%pred_anchor_deltas.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:525:8
                %14 : int[] = prim::ListConstruct(%12, %13)
                %15 : int = prim::min(%14) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:525:8
                 = prim::Loop(%15, %16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:525:8
                  block0(%17 : int):
                    %anchors_i.1 : __torch__.detectron2.structures.boxes.Boxes = aten::__getitem__(%anchors.1, %17) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:525:8
                    %pred_anchor_deltas_i.1 : Tensor = aten::__getitem__(%pred_anchor_deltas.1, %17) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:525:8
                    %tensor.1 : Tensor = prim::GetAttr[name="tensor"](%anchors_i.1)
                    %B.1 : int = aten::size(%tensor.1, %23) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:526:16
                    %29 : int[] = prim::ListConstruct(%27, %B.1)
                    %pred_anchor_deltas_i.5 : Tensor = aten::reshape(%pred_anchor_deltas_i.1, %29) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:527:35
                    %tensor : Tensor = prim::GetAttr[name="tensor"](%anchors_i.1)
                    %33 : Tensor = aten::unsqueeze(%tensor, %5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:529:24
                    %39 : int[] = prim::ListConstruct(%N.1, %27, %27)
                    %41 : Tensor = aten::expand(%33, %39, %40) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:529:24
                    %45 : int[] = prim::ListConstruct(%27, %B.1)
                    %anchors_i.7 : Tensor = aten::reshape(%41, %45) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:529:24
                    %box2box_transform : __torch__.detectron2.modeling.box_regression.Box2BoxTransform = prim::GetAttr[name="box2box_transform"](%self)
                    %proposals_i.1 : Tensor = prim::CallMethod[name="apply_deltas"](%box2box_transform, %pred_anchor_deltas_i.5, %anchors_i.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:530:26
                    %57 : int[] = prim::ListConstruct(%N.1, %27, %B.1)
                    %58 : Tensor = aten::view(%proposals_i.1, %57) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:532:29
                    %59 : Tensor[] = aten::append(%proposals.1, %58) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:532:12
                    -> (%16)
                return (%proposals.1)
          
            }
          }
          submodules {
            module __torch__.detectron2.modeling.proposal_generator.rpn.StandardRPNHead {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                conv = <__torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d object at 0xa9e0810>
                objectness_logits = <__torch__.torch.nn.modules.conv.Conv2d object at 0xde749c0>
                anchor_deltas = <__torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d object at 0xde6f6a0>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.proposal_generator.rpn.StandardRPNHead,
                        %features.1 : Tensor[]):
                    %7 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:173:8
                    %pred_objectness_logits.1 : Tensor[] = prim::ListConstruct()
                    %pred_anchor_deltas.1 : Tensor[] = prim::ListConstruct()
                    %6 : int = aten::len(%features.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:173:8
                     = prim::Loop(%6, %7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:173:8
                      block0(%8 : int):
                        %x.1 : Tensor = aten::__getitem__(%features.1, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:173:8
                        %conv : __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d = prim::GetAttr[name="conv"](%self)
                        %t.1 : Tensor = prim::CallMethod[name="forward"](%conv, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:174:16
                        %objectness_logits : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="objectness_logits"](%self)
                        %16 : Tensor = prim::CallMethod[name="forward"](%objectness_logits, %t.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:175:42
                        %17 : Tensor[] = aten::append(%pred_objectness_logits.1, %16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:175:12
                        %anchor_deltas : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d = prim::GetAttr[name="anchor_deltas"](%self)
                        %21 : Tensor = prim::CallMethod[name="forward"](%anchor_deltas, %t.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:176:38
                        %22 : Tensor[] = aten::append(%pred_anchor_deltas.1, %21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/proposal_generator/rpn.py:176:12
                        -> (%7)
                    %25 : (Tensor[], Tensor[]) = prim::TupleConstruct(%pred_objectness_logits.1, %pred_anchor_deltas.1)
                    return (%25)
              
                }
              }
              submodules {
                module __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = <__torch__.torch.nn.modules.activation.ReLU object at 0x120d8270>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %activation : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="activation"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%activation, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:117:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.activation.ReLU {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                                %input.1 : Tensor):
                            %4 : Function = prim::Constant[name="relu"]()
                            %3 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:37
                            %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:15
                            return (%5)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.torch.nn.modules.conv.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.conv.Conv2d,
                            %input.1 : Tensor):
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %5 : Tensor = prim::CallMethod[name="_conv_forward"](%self, %input.1, %weight, %bias) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:446:15
                        return (%5)
                  
                    }
                    method _conv_forward {
                      graph(%self : __torch__.torch.nn.modules.conv.Conv2d,
                            %input.1 : Tensor,
                            %weight.1 : Tensor,
                            %bias.1 : Tensor?):
                        %61 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:24
                        %58 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:442:45
                        %68 : int[] = prim::ListConstruct(%58, %58)
                        %69 : int[] = prim::ListConstruct(%61, %61)
                        %70 : int[] = prim::ListConstruct(%58, %58)
                        %71 : Tensor = aten::conv2d(%input.1, %weight.1, %bias.1, %68, %69, %70, %58) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:442:15
                        return (%71)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d,
                            %input.1 : Tensor):
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %5 : Tensor = prim::CallMethod[name="_conv_forward"](%self, %input.1, %weight, %bias) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:446:15
                        return (%5)
                  
                    }
                    method _conv_forward {
                      graph(%self : __torch__.torch.nn.modules.conv.___torch_mangle_40.Conv2d,
                            %input.1 : Tensor,
                            %weight.1 : Tensor,
                            %bias.1 : Tensor?):
                        %61 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:443:24
                        %58 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:442:45
                        %68 : int[] = prim::ListConstruct(%58, %58)
                        %69 : int[] = prim::ListConstruct(%61, %61)
                        %70 : int[] = prim::ListConstruct(%58, %58)
                        %71 : Tensor = aten::conv2d(%input.1, %weight.1, %bias.1, %68, %69, %70, %58) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:442:15
                        return (%71)
                  
                    }
                  }
                  submodules {
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                strides = [4, 8, 16, 32, 64]
                num_features = 5
                offset = 0.
                cell_anchors = <__torch__.detectron2.modeling.anchor_generator.BufferList object at 0x8520780>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator,
                        %features.1 : Tensor[]):
                    %15 : NoneType = prim::Constant()
                    %14 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:229:22
                    %13 : int = prim::Constant[value=-2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:229:40
                    %6 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:229:21
                    %grid_sizes.1 : int[][] = prim::ListConstruct()
                    %5 : int = aten::len(%features.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:229:21
                     = prim::Loop(%5, %6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:229:21
                      block0(%7 : int):
                        %feature_map.1 : Tensor = aten::__getitem__(%features.1, %7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:229:21
                        %10 : int[] = aten::size(%feature_map.1) # <string>:7:9
                        %16 : int[] = aten::slice(%10, %13, %15, %14) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:229:22
                        %17 : int[][] = aten::append(%grid_sizes.1, %16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:229:21
                        -> (%6)
                    %anchors_over_all_feature_maps.1 : Tensor[] = prim::CallMethod[name="_grid_anchors"](%self, %grid_sizes.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:230:40
                    %20 : __torch__.detectron2.structures.boxes.Boxes[] = prim::ListConstruct()
                    %22 : int = aten::len(%anchors_over_all_feature_maps.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:231:15
                     = prim::Loop(%22, %6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:231:15
                      block0(%24 : int):
                        %x.1 : Tensor = aten::__getitem__(%anchors_over_all_feature_maps.1, %24) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:231:15
                        %27 : __torch__.detectron2.structures.boxes.Boxes = prim::CreateObject()
                        %28 : NoneType = prim::CallMethod[name="__init__"](%27, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:231:16
                        %29 : __torch__.detectron2.structures.boxes.Boxes[] = aten::append(%20, %27) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:231:15
                        -> (%6)
                    return (%20)
              
                }
                method _grid_anchors {
                  graph(%self : __torch__.detectron2.modeling.anchor_generator.DefaultAnchorGenerator,
                        %grid_sizes.1 : int[][]):
                    %78 : int = prim::Constant[value=-1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:177:40
                    %64 : Function = prim::Constant[name="_create_grid_offsets"]()
                    %54 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:173:8
                    %23 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:172:41
                    %41 : int = prim::Constant[value=4]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:172:38
                    %anchors.1 : Tensor[] = prim::ListConstruct()
                    %buffers.1 : Tensor[] = prim::ListConstruct()
                    %cell_anchors : __torch__.detectron2.modeling.anchor_generator.BufferList = prim::GetAttr[name="cell_anchors"](%self)
                    %_0 : Tensor = prim::GetAttr[name="0"](%cell_anchors)
                    %_1 : Tensor = prim::GetAttr[name="1"](%cell_anchors)
                    %_2 : Tensor = prim::GetAttr[name="2"](%cell_anchors)
                    %_3 : Tensor = prim::GetAttr[name="3"](%cell_anchors)
                    %_4 : Tensor = prim::GetAttr[name="4"](%cell_anchors)
                    %26 : Tensor[] = aten::append(%buffers.1, %_0) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:172:38
                    %30 : Tensor[] = aten::append(%buffers.1, %_1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:172:38
                    %35 : Tensor[] = aten::append(%buffers.1, %_2) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:172:38
                    %40 : Tensor[] = aten::append(%buffers.1, %_3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:172:38
                    %45 : Tensor[] = aten::append(%buffers.1, %_4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:172:38
                    %strides : int[] = prim::GetAttr[name="strides"](%self)
                    %49 : int = aten::len(%grid_sizes.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:173:8
                    %50 : int = aten::len(%strides) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:173:8
                    %51 : int = aten::len(%buffers.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:173:8
                    %52 : int[] = prim::ListConstruct(%49, %50, %51)
                    %53 : int = prim::min(%52) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:173:8
                     = prim::Loop(%53, %54) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:173:8
                      block0(%55 : int):
                        %size.1 : int[] = aten::__getitem__(%grid_sizes.1, %55) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:173:8
                        %stride.1 : int = aten::__getitem__(%strides, %55) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:173:8
                        %base_anchors.1 : Tensor = aten::__getitem__(%buffers.1, %55) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:173:8
                        %offset : float = prim::GetAttr[name="offset"](%self)
                        %65 : (Tensor, Tensor) = prim::CallFunction(%64, %size.1, %stride.1, %offset, %base_anchors.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:174:31
                        %shift_x.1 : Tensor, %shift_y.1 : Tensor = prim::TupleUnpack(%65)
                        %73 : Tensor[] = prim::ListConstruct(%shift_x.1, %shift_y.1, %shift_x.1, %shift_y.1)
                        %shifts.1 : Tensor = aten::stack(%73, %23) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:175:21
                        %79 : int[] = prim::ListConstruct(%78, %23, %41)
                        %80 : Tensor = aten::view(%shifts.1, %79) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:177:28
                        %84 : int[] = prim::ListConstruct(%23, %78, %41)
                        %85 : Tensor = aten::view(%base_anchors.1, %84) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:177:52
                        %87 : Tensor = aten::add(%80, %85, %23) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:177:28
                        %90 : int[] = prim::ListConstruct(%78, %41)
                        %91 : Tensor = aten::reshape(%87, %90) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:177:28
                        %92 : Tensor[] = aten::append(%anchors.1, %91) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/anchor_generator.py:177:12
                        -> (%54)
                    return (%anchors.1)
              
                }
              }
              submodules {
                module __torch__.detectron2.modeling.anchor_generator.BufferList {
                  parameters {
                  }
                  attributes {
                    0 = ...
                    1 = ...
                    2 = ...
                    3 = ...
                    4 = ...
                    _is_full_backward_hook = None
                  }
                  methods {
                  }
                  submodules {
                  }
                }
              }
            }
          }
        }
        module __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads {
          parameters {
          }
          attributes {
            _is_full_backward_hook = None
            batch_size_per_image = 512
            positive_fraction = 0.25
            num_classes = 2
            proposal_matcher = <__torch__.detectron2.modeling.matcher.Matcher object at 0x627b0c0>
            proposal_append_gt = True
            in_features = [p2, p3, p4, p5]
            box_in_features = [p2, p3, p4, p5]
            mask_in_features = [p2, p3, p4, p5]
            train_on_pred_boxes = False
            box_pooler = <__torch__.detectron2.modeling.poolers.ROIPooler object at 0x625bf70>
            box_head = <__torch__.detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead object at 0x62421d0>
            box_predictor = <__torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers object at 0x6403d20>
            mask_pooler = <__torch__.detectron2.modeling.poolers.ROIPooler object at 0xde69970>
            mask_head = <__torch__.detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead object at 0x84fdaf0>
          }
          methods {
            method forward {
              graph(%self : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
                    %images : __torch__.detectron2.structures.image_list.ImageList,
                    %features.1 : Dict(str, Tensor),
                    %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[],
                    %targets : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]?):
                %pred_instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="_forward_box"](%self, %features.1, %proposals.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:747:29
                %pred_instances.5 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="forward_with_given_boxes"](%self, %features.1, %pred_instances.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:750:29
                %17 : Dict(str, Tensor) = prim::DictConstruct()
                %18 : (__torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], Dict(str, Tensor)) = prim::TupleConstruct(%pred_instances.5, %17)
                return (%18)
          
            }
            method _forward_box {
              graph(%self : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
                    %features.1 : Dict(str, Tensor),
                    %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                %7 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:797:19
                %features.5 : Tensor[] = prim::ListConstruct()
                %box_in_features : str[] = prim::GetAttr[name="box_in_features"](%self)
                %6 : int = aten::len(%box_in_features) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:797:19
                 = prim::Loop(%6, %7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:797:19
                  block0(%8 : int):
                    %f.1 : str = aten::__getitem__(%box_in_features, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:797:19
                    %12 : Tensor = aten::__getitem__(%features.1, %f.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:797:20
                    %13 : Tensor[] = aten::append(%features.5, %12) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:797:19
                    -> (%7)
                %box_pooler : __torch__.detectron2.modeling.poolers.ROIPooler = prim::GetAttr[name="box_pooler"](%self)
                %16 : __torch__.detectron2.structures.boxes.Boxes[] = prim::ListConstruct()
                %18 : int = aten::len(%proposals.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:798:49
                 = prim::Loop(%18, %7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:798:49
                  block0(%20 : int):
                    %x.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%proposals.1, %20) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:798:49
                    %23 : __torch__.detectron2.structures.boxes.Boxes = prim::CallMethod[name="__proposal_boxes_getter"](%x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:798:50
                    %24 : __torch__.detectron2.structures.boxes.Boxes[] = aten::append(%16, %23) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:798:49
                    -> (%7)
                %box_features.1 : Tensor = prim::CallMethod[name="forward"](%box_pooler, %features.5, %16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:798:23
                %box_head : __torch__.detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead = prim::GetAttr[name="box_head"](%self)
                %box_features.5 : Tensor = prim::CallMethod[name="forward"](%box_head, %box_features.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:799:23
                %box_predictor.1 : __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers = prim::GetAttr[name="box_predictor"](%self)
                %predictions.1 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%box_predictor.1, %box_features.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:800:22
                %box_predictor : __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers = prim::GetAttr[name="box_predictor"](%self)
                %37 : (__torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], Tensor[]) = prim::CallMethod[name="inference"](%box_predictor, %predictions.1, %proposals.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:815:32
                %pred_instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], %39 : Tensor[] = prim::TupleUnpack(%37)
                return (%pred_instances.1)
          
            }
            method forward_with_given_boxes {
              graph(%self : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
                    %features.1 : Dict(str, Tensor),
                    %instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                %44 : str = prim::Constant[value="AssertionError: "]()
                %22 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:774:15
                %19 : str = prim::Constant[value="pred_classes"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:774:67
                %12 : str = prim::Constant[value="pred_boxes"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:774:32
                %8 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:774:25
                %11 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%instances.1, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:774:15
                %13 : bool = prim::CallMethod[name="has"](%11, %12) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:774:15
                %23 : bool = prim::If(%13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:774:15
                  block0():
                    %18 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%instances.1, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:774:50
                    %20 : bool = prim::CallMethod[name="has"](%18, %19) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:774:50
                    -> (%20)
                  block1():
                    -> (%22)
                 = prim::If(%23) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:774:8
                  block0():
                    -> ()
                  block1():
                     = prim::RaiseException(%44) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:774:8
                    -> ()
                %instances.13 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="_forward_mask"](%self, %features.1, %instances.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:776:20
                %instances.17 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="_forward_keypoint"](%self, %features.1, %instances.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:777:20
                return (%instances.17)
          
            }
            method _forward_mask {
              graph(%self : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
                    %features.1 : Dict(str, Tensor),
                    %instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                %15 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:841:23
                %features.5 : Tensor[] = prim::ListConstruct()
                %mask_in_features : str[] = prim::GetAttr[name="mask_in_features"](%self)
                %14 : int = aten::len(%mask_in_features) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:841:23
                 = prim::Loop(%14, %15) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:841:23
                  block0(%16 : int):
                    %f.1 : str = aten::__getitem__(%mask_in_features, %16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:841:23
                    %20 : Tensor = aten::__getitem__(%features.1, %f.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:841:24
                    %21 : Tensor[] = aten::append(%features.5, %20) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:841:23
                    -> (%15)
                %boxes.1 : __torch__.detectron2.structures.boxes.Boxes[] = prim::ListConstruct()
                %24 : int = aten::len(%instances.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:842:20
                 = prim::Loop(%24, %15) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:842:20
                  block0(%26 : int):
                    %x.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%instances.1, %26) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:842:20
                    %31 : __torch__.detectron2.structures.boxes.Boxes = prim::CallMethod[name="__pred_boxes_getter"](%x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:842:60
                    %32 : __torch__.detectron2.structures.boxes.Boxes[] = aten::append(%boxes.1, %31) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:842:20
                    -> (%15)
                %mask_pooler : __torch__.detectron2.modeling.poolers.ROIPooler = prim::GetAttr[name="mask_pooler"](%self)
                %features.9 : Tensor = prim::CallMethod[name="forward"](%mask_pooler, %features.5, %boxes.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:843:23
                %mask_head : __torch__.detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead = prim::GetAttr[name="mask_head"](%self)
                %40 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[] = prim::CallMethod[name="forward"](%mask_head, %features.9, %instances.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/roi_heads.py:846:15
                return (%40)
          
            }
            method _forward_keypoint {
              graph(%self : __torch__.detectron2.modeling.roi_heads.roi_heads.StandardROIHeads,
                    %features : Dict(str, Tensor),
                    %instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                return (%instances.1)
          
            }
          }
          submodules {
            module __torch__.detectron2.modeling.poolers.ROIPooler {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                output_size = (7, 7)
                min_level = 2
                max_level = 5
                canonical_level = 4
                canonical_box_size = 224
                level_poolers = <__torch__.torch.nn.modules.container.___torch_mangle_41.ModuleList object at 0x6256a00>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.poolers.ROIPooler,
                        %x.1 : Tensor[],
                        %box_lists.1 : __torch__.detectron2.structures.boxes.Boxes[]):
                    %363 : bool = prim::Constant[value=0]()
                    %354 : Function = prim::Constant[name="nonzero_tuple"]()
                    %332 : Function = prim::Constant[name="assign_boxes_to_levels"]()
                    %234 : Function = prim::Constant[name="convert_boxes_to_pooler_format"]()
                    %65 : Function = prim::Constant[name="_create_zeros"]()
                    %54 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:237:33
                    %40 : str = prim::Constant[value="unequal value, x[0] batch dim 0 is {}, but box_list has length {}"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:233:11
                    %29 : str = prim::Constant[value="AssertionError: "]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:225:8
                    %24 : str = prim::Constant[value="unequal value, num_level_assignments={}, but x is list of {} Tensors"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:227:11
                    %level.1 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:35
                    %level.7 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:237:50
                    %level.13 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:253:8
                    %level.19 : int = prim::Constant[value=3]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:253:8
                    %level_poolers.1 : __torch__.torch.nn.modules.container.___torch_mangle_41.ModuleList = prim::GetAttr[name="level_poolers"](%self)
                    %num_level_assignments.1 : int = prim::CallMethod[name="__len__"](%level_poolers.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:220:32
                    %x.7 : Tensor[] = prim::unchecked_cast(%x.1)
                    %x.13 : Tensor[] = prim::unchecked_cast(%x.7)
                    %box_lists.7 : __torch__.detectron2.structures.boxes.Boxes[] = prim::unchecked_cast(%box_lists.1)
                    %20 : int = aten::len(%x.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:226:12
                    %22 : bool = aten::eq(%20, %num_level_assignments.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:226:12
                     = prim::If(%22) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:225:8
                      block0():
                        -> ()
                      block1():
                        %27 : int = aten::len(%x.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:228:35
                        %28 : str = aten::format(%24, %num_level_assignments.1, %27) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:227:11
                        %30 : str = aten::add(%29, %28) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:225:8
                         = prim::RaiseException(%30) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:225:8
                        -> ()
                    %33 : int = aten::len(%box_lists.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:15
                    %36 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:33
                    %37 : int = aten::size(%36, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:33
                    %38 : bool = aten::eq(%33, %37) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:15
                     = prim::If(%38) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:8
                      block0():
                        -> ()
                      block1():
                        %42 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:234:12
                        %43 : int = aten::size(%42, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:234:12
                        %45 : int = aten::len(%box_lists.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:234:26
                        %46 : str = aten::format(%40, %43, %45) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:233:11
                        %48 : str = aten::add(%29, %46) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:8
                         = prim::RaiseException(%48) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:8
                        -> ()
                    %51 : int = aten::len(%box_lists.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:236:11
                    %52 : bool = aten::eq(%51, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:236:11
                    %327 : Tensor = prim::If(%52) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:236:8
                      block0():
                        %56 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:237:39
                        %57 : int[] = aten::size(%56) # <string>:7:9
                        %59 : int = aten::__getitem__(%57, %level.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:237:39
                        %output_size.1 : (int, int) = prim::GetAttr[name="output_size"](%self)
                        %61 : int, %62 : int = prim::TupleUnpack(%output_size.1)
                        %64 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:237:73
                        %66 : Tensor = prim::CallFunction(%65, %54, %59, %61, %62, %64) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:237:19
                        -> (%66)
                      block1():
                        %pooler_fmt_boxes.13 : Tensor = prim::CallFunction(%234, %box_lists.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:239:27
                        %236 : bool = aten::eq(%num_level_assignments.1, %level.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:241:11
                        %402 : Tensor = prim::If(%236) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:241:8
                          block0():
                            %level_poolers.5 : __torch__.torch.nn.modules.container.___torch_mangle_41.ModuleList = prim::GetAttr[name="level_poolers"](%self)
                            %_0.3 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="0"](%level_poolers.5)
                            %249 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:242:41
                            %250 : Tensor = prim::CallMethod[name="forward"](%_0.3, %249, %pooler_fmt_boxes.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:242:19
                            -> (%250)
                          block1():
                            %min_level.5 : int = prim::GetAttr[name="min_level"](%self)
                            %max_level.5 : int = prim::GetAttr[name="max_level"](%self)
                            %canonical_box_size.5 : int = prim::GetAttr[name="canonical_box_size"](%self)
                            %canonical_level.5 : int = prim::GetAttr[name="canonical_level"](%self)
                            %level_assignments.13 : Tensor = prim::CallFunction(%332, %box_lists.7, %min_level.5, %max_level.5, %canonical_box_size.5, %canonical_level.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:244:28
                            %334 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:248:23
                            %335 : int[] = aten::size(%334) # <string>:7:9
                            %num_channels.7 : int = aten::__getitem__(%335, %level.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:248:23
                            %output_size.17 : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %output_size.21 : int = prim::TupleIndex(%output_size.17, %level.1)
                            %339 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:251:89
                            %output.15 : Tensor = prim::CallFunction(%65, %pooler_fmt_boxes.13, %num_channels.7, %output_size.21, %output_size.21, %339) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:251:17
                            %level_poolers.13 : __torch__.torch.nn.modules.container.___torch_mangle_41.ModuleList = prim::GetAttr[name="level_poolers"](%self)
                            %_0.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="0"](%level_poolers.13)
                            %_1.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="1"](%level_poolers.13)
                            %_2.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="2"](%level_poolers.13)
                            %_3.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="3"](%level_poolers.13)
                            %353 : Tensor = aten::eq(%level_assignments.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:33
                            %355 : Tensor[] = prim::CallFunction(%354, %353) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %inds.55 : Tensor = aten::__getitem__(%355, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %357 : Tensor?[] = prim::ListConstruct(%inds.55)
                            %pooler_fmt_boxes_level.31 : Tensor = aten::index(%pooler_fmt_boxes.13, %357) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:255:37
                            %360 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:46
                            %361 : Tensor = prim::CallMethod[name="forward"](%_0.11, %360, %pooler_fmt_boxes_level.31) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:39
                            %362 : Tensor?[] = prim::ListConstruct(%inds.55)
                            %364 : Tensor = aten::index_put_(%output.15, %362, %361, %363) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:12
                            %365 : Tensor = aten::eq(%level_assignments.13, %level.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:33
                            %367 : Tensor[] = prim::CallFunction(%354, %365) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %inds.59 : Tensor = aten::__getitem__(%367, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %369 : Tensor?[] = prim::ListConstruct(%inds.59)
                            %pooler_fmt_boxes_level.35 : Tensor = aten::index(%pooler_fmt_boxes.13, %369) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:255:37
                            %372 : Tensor = aten::__getitem__(%x.13, %level.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:46
                            %373 : Tensor = prim::CallMethod[name="forward"](%_1.11, %372, %pooler_fmt_boxes_level.35) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:39
                            %374 : Tensor?[] = prim::ListConstruct(%inds.59)
                            %376 : Tensor = aten::index_put_(%output.15, %374, %373, %363) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:12
                            %377 : Tensor = aten::eq(%level_assignments.13, %level.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:33
                            %379 : Tensor[] = prim::CallFunction(%354, %377) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %inds.63 : Tensor = aten::__getitem__(%379, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %381 : Tensor?[] = prim::ListConstruct(%inds.63)
                            %pooler_fmt_boxes_level.39 : Tensor = aten::index(%pooler_fmt_boxes.13, %381) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:255:37
                            %384 : Tensor = aten::__getitem__(%x.13, %level.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:46
                            %385 : Tensor = prim::CallMethod[name="forward"](%_2.11, %384, %pooler_fmt_boxes_level.39) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:39
                            %386 : Tensor?[] = prim::ListConstruct(%inds.63)
                            %388 : Tensor = aten::index_put_(%output.15, %386, %385, %363) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:12
                            %389 : Tensor = aten::eq(%level_assignments.13, %level.19) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:33
                            %391 : Tensor[] = prim::CallFunction(%354, %389) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %inds.67 : Tensor = aten::__getitem__(%391, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %393 : Tensor?[] = prim::ListConstruct(%inds.67)
                            %pooler_fmt_boxes_level.43 : Tensor = aten::index(%pooler_fmt_boxes.13, %393) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:255:37
                            %396 : Tensor = aten::__getitem__(%x.13, %level.19) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:46
                            %397 : Tensor = prim::CallMethod[name="forward"](%_3.11, %396, %pooler_fmt_boxes_level.43) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:39
                            %398 : Tensor?[] = prim::ListConstruct(%inds.67)
                            %400 : Tensor = aten::index_put_(%output.15, %398, %397, %363) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:12
                            -> (%output.15)
                        -> (%402)
                    return (%327)
              
                }
              }
              submodules {
                module __torch__.torch.nn.modules.container.___torch_mangle_41.ModuleList {
                  parameters {
                  }
                  attributes {
                    _is_full_backward_hook = None
                    0 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0xaacb350>
                    1 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x84fca10>
                    2 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x622d4b0>
                    3 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x6266a60>
                  }
                  methods {
                    method __len__ {
                      graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_41.ModuleList):
                        %1 : int = prim::Constant[value=4]() # <string>:2:10
                        return (%1)
                  
                    }
                  }
                  submodules {
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (7, 7)
                        spatial_scale = 0.25
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %46 : Function = prim::Constant[name="roi_align"]()
                            %37 : NoneType = prim::Constant()
                            %60 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %22 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%22) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %34 : int = prim::dtype(%input)
                            %38 : Tensor = aten::to(%rois.1, %34, %15, %15, %37) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %43 : int, %44 : int = prim::TupleUnpack(%output_size)
                            %45 : int[] = prim::ListConstruct(%43, %44)
                            %47 : Tensor = prim::CallFunction(%46, %input, %38, %45, %spatial_scale, %sampling_ratio, %aligned) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:58:15
                            return (%47)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (7, 7)
                        spatial_scale = 0.125
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %46 : Function = prim::Constant[name="roi_align"]()
                            %37 : NoneType = prim::Constant()
                            %60 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %22 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%22) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %34 : int = prim::dtype(%input)
                            %38 : Tensor = aten::to(%rois.1, %34, %15, %15, %37) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %43 : int, %44 : int = prim::TupleUnpack(%output_size)
                            %45 : int[] = prim::ListConstruct(%43, %44)
                            %47 : Tensor = prim::CallFunction(%46, %input, %38, %45, %spatial_scale, %sampling_ratio, %aligned) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:58:15
                            return (%47)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (7, 7)
                        spatial_scale = 0.0625
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %46 : Function = prim::Constant[name="roi_align"]()
                            %37 : NoneType = prim::Constant()
                            %60 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %22 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%22) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %34 : int = prim::dtype(%input)
                            %38 : Tensor = aten::to(%rois.1, %34, %15, %15, %37) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %43 : int, %44 : int = prim::TupleUnpack(%output_size)
                            %45 : int[] = prim::ListConstruct(%43, %44)
                            %47 : Tensor = prim::CallFunction(%46, %input, %38, %45, %spatial_scale, %sampling_ratio, %aligned) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:58:15
                            return (%47)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (7, 7)
                        spatial_scale = 0.03125
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %46 : Function = prim::Constant[name="roi_align"]()
                            %37 : NoneType = prim::Constant()
                            %60 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %22 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%22) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %34 : int = prim::dtype(%input)
                            %38 : Tensor = aten::to(%rois.1, %34, %15, %15, %37) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %43 : int, %44 : int = prim::TupleUnpack(%output_size)
                            %45 : int[] = prim::ListConstruct(%43, %44)
                            %47 : Tensor = prim::CallFunction(%46, %input, %38, %45, %spatial_scale, %sampling_ratio, %aligned) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:58:15
                            return (%47)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                _output_size = 1024
                flatten = <__torch__.torch.nn.modules.flatten.Flatten object at 0x8503850>
                fc1 = <__torch__.torch.nn.modules.linear.Linear object at 0x61fbd70>
                fc_relu1 = <__torch__.torch.nn.modules.activation.ReLU object at 0x629b8a0>
                fc2 = <__torch__.torch.nn.modules.linear.___torch_mangle_42.Linear object at 0x85384a0>
                fc_relu2 = <__torch__.torch.nn.modules.activation.ReLU object at 0x62a63a0>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead,
                        %x.1 : Tensor):
                    %flatten : __torch__.torch.nn.modules.flatten.Flatten = prim::GetAttr[name="flatten"](%self)
                    %fc1 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="fc1"](%self)
                    %fc_relu1 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="fc_relu1"](%self)
                    %fc2 : __torch__.torch.nn.modules.linear.___torch_mangle_42.Linear = prim::GetAttr[name="fc2"](%self)
                    %fc_relu2 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="fc_relu2"](%self)
                    %x.5 : Tensor = prim::CallMethod[name="forward"](%flatten, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/box_head.py:96:16
                    %x.9 : Tensor = prim::CallMethod[name="forward"](%fc1, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/box_head.py:96:16
                    %x.13 : Tensor = prim::CallMethod[name="forward"](%fc_relu1, %x.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/box_head.py:96:16
                    %x.17 : Tensor = prim::CallMethod[name="forward"](%fc2, %x.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/box_head.py:96:16
                    %x.21 : Tensor = prim::CallMethod[name="forward"](%fc_relu2, %x.17) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/box_head.py:96:16
                    return (%x.21)
              
                }
                method __len__ {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.box_head.FastRCNNConvFCHead):
                    %1 : int = prim::Constant[value=5]() # <string>:2:10
                    return (%1)
              
                }
              }
              submodules {
                module __torch__.torch.nn.modules.flatten.Flatten {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.flatten.Flatten,
                            %input.1 : Tensor):
                        %4 : int = prim::Constant[value=-1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/flatten.py:42:45
                        %3 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/flatten.py:42:29
                        %5 : Tensor = aten::flatten(%input.1, %3, %4) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/flatten.py:42:15
                        return (%5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.linear.Linear {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.linear.Linear,
                            %input.1 : Tensor):
                        %5 : Function = prim::Constant[name="linear"]()
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                        %6 : Tensor = prim::CallFunction(%5, %input.1, %weight, %bias) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/linear.py:103:15
                        return (%6)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.activation.ReLU {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                            %input.1 : Tensor):
                        %4 : Function = prim::Constant[name="relu"]()
                        %3 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:37
                        %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:15
                        return (%5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.linear.___torch_mangle_42.Linear {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.linear.___torch_mangle_42.Linear,
                            %input.1 : Tensor):
                        %5 : Function = prim::Constant[name="linear"]()
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                        %6 : Tensor = prim::CallFunction(%5, %input.1, %weight, %bias) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/linear.py:103:15
                        return (%6)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.activation.ReLU {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                            %input.1 : Tensor):
                        %4 : Function = prim::Constant[name="relu"]()
                        %3 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:37
                        %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:15
                        return (%5)
                  
                    }
                  }
                  submodules {
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                num_classes = 2
                box2box_transform = <__torch__.detectron2.modeling.box_regression.Box2BoxTransform object at 0xdc1a1e0>
                smooth_l1_beta = 0.
                test_score_thresh = 0.050000000000000003
                test_nms_thresh = 0.5
                test_topk_per_image = 100
                box_reg_loss_type = smooth_l1
                loss_weight = {loss_cls: 1., loss_box_reg: 1.}
                use_fed_loss = False
                use_sigmoid_ce = False
                fed_loss_num_classes = 50
                cls_score = <__torch__.torch.nn.modules.linear.___torch_mangle_43.Linear object at 0x62a7b40>
                bbox_pred = <__torch__.torch.nn.modules.linear.___torch_mangle_44.Linear object at 0x9b94020>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers,
                        %x.1 : Tensor):
                    %10 : int = prim::Constant[value=-1]()
                    %5 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:301:21
                    %9 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:302:43
                    %4 : int = aten::dim(%x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:301:11
                    %6 : bool = aten::gt(%4, %5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:301:11
                    %x : Tensor = prim::If(%6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:301:8
                      block0():
                        %x.7 : Tensor = aten::flatten(%x.1, %9, %10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:302:16
                        -> (%x.7)
                      block1():
                        -> (%x.1)
                    %cls_score : __torch__.torch.nn.modules.linear.___torch_mangle_43.Linear = prim::GetAttr[name="cls_score"](%self)
                    %scores.1 : Tensor = prim::CallMethod[name="forward"](%cls_score, %x) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:303:17
                    %bbox_pred : __torch__.torch.nn.modules.linear.___torch_mangle_44.Linear = prim::GetAttr[name="bbox_pred"](%self)
                    %proposal_deltas.1 : Tensor = prim::CallMethod[name="forward"](%bbox_pred, %x) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:304:26
                    %25 : (Tensor, Tensor) = prim::TupleConstruct(%scores.1, %proposal_deltas.1)
                    return (%25)
              
                }
                method inference {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers,
                        %predictions.1 : (Tensor, Tensor),
                        %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                    %25 : Function = prim::Constant[name="fast_rcnn_inference"]()
                    %13 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:478:23
                    %boxes.1 : Tensor[] = prim::CallMethod[name="predict_boxes"](%self, %predictions.1, %proposals.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:476:16
                    %scores.1 : Tensor[] = prim::CallMethod[name="predict_probs"](%self, %predictions.1, %proposals.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:477:17
                    %image_shapes.1 : (int, int)[] = prim::ListConstruct()
                    %12 : int = aten::len(%proposals.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:478:23
                     = prim::Loop(%12, %13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:478:23
                      block0(%14 : int):
                        %x.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%proposals.1, %14) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:478:23
                        %image_size : (int, int) = prim::GetAttr[name="image_size"](%x.1)
                        %18 : (int, int)[] = aten::append(%image_shapes.1, %image_size) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:478:23
                        -> (%13)
                    %test_score_thresh : float = prim::GetAttr[name="test_score_thresh"](%self)
                    %test_nms_thresh : float = prim::GetAttr[name="test_nms_thresh"](%self)
                    %test_topk_per_image : int = prim::GetAttr[name="test_topk_per_image"](%self)
                    %26 : (__torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[], Tensor[]) = prim::CallFunction(%25, %boxes.1, %scores.1, %image_shapes.1, %test_score_thresh, %test_nms_thresh, %test_topk_per_image) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:479:15
                    return (%26)
              
                }
                method predict_boxes {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers,
                        %predictions.1 : (Tensor, Tensor),
                        %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                    %74 : Function = prim::Constant[name="cat"]()
                    %61 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:541:29
                    %32 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:542:79
                    %5 : int = aten::len(%proposals.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:538:15
                    %7 : bool = aten::Bool(%5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:538:15
                    %8 : bool = aten::__not__(%7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:538:11
                    %81 : Tensor[] = prim::If(%8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:538:8
                      block0():
                        %9 : Tensor[] = prim::ListConstruct()
                        -> (%9)
                      block1():
                        %57 : Tensor, %proposal_deltas.3 : Tensor = prim::TupleUnpack(%predictions.1)
                        %num_prop_per_image.3 : int[] = prim::ListConstruct()
                        %60 : int = aten::len(%proposals.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:541:29
                         = prim::Loop(%60, %61) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:541:29
                          block0(%62 : int):
                            %p.7 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%proposals.1, %62) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:541:29
                            %64 : int = prim::CallMethod[name="__len__"](%p.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:541:30
                            %65 : int[] = aten::append(%num_prop_per_image.3, %64) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:541:29
                            -> (%61)
                        %66 : Tensor[] = prim::ListConstruct()
                        %67 : int = aten::len(%proposals.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:542:29
                         = prim::Loop(%67, %61) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:542:29
                          block0(%69 : int):
                            %p.11 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%proposals.1, %69) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:542:29
                            %71 : __torch__.detectron2.structures.boxes.Boxes = prim::CallMethod[name="__proposal_boxes_getter"](%p.11) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:542:30
                            %tensor.1 : Tensor = prim::GetAttr[name="tensor"](%71)
                            %73 : Tensor[] = aten::append(%66, %tensor.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:542:29
                            -> (%61)
                        %proposal_boxes.3 : Tensor = prim::CallFunction(%74, %66, %32) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:542:25
                        %box2box_transform.1 : __torch__.detectron2.modeling.box_regression.Box2BoxTransform = prim::GetAttr[name="box2box_transform"](%self)
                        %predict_boxes.3 : Tensor = prim::CallMethod[name="apply_deltas"](%box2box_transform.1, %proposal_deltas.3, %proposal_boxes.3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:543:24
                        %79 : Tensor[] = aten::split(%predict_boxes.3, %num_prop_per_image.3, %32) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:547:15
                        -> (%79)
                    return (%81)
              
                }
                method predict_probs {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers,
                        %predictions.1 : (Tensor, Tensor),
                        %proposals.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                    %26 : Function = prim::Constant[name="softmax"]()
                    %25 : NoneType = prim::Constant()
                    %24 : int = prim::Constant[value=3]()
                    %23 : int = prim::Constant[value=-1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:568:42
                    %10 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:564:29
                    %34 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:569:51
                    %scores.1 : Tensor, %6 : Tensor = prim::TupleUnpack(%predictions.1)
                    %num_inst_per_image.1 : int[] = prim::ListConstruct()
                    %9 : int = aten::len(%proposals.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:564:29
                     = prim::Loop(%9, %10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:564:29
                      block0(%11 : int):
                        %p.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1 = aten::__getitem__(%proposals.1, %11) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:564:29
                        %14 : int = prim::CallMethod[name="__len__"](%p.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:564:30
                        %15 : int[] = aten::append(%num_inst_per_image.1, %14) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:564:29
                        -> (%10)
                    %use_sigmoid_ce : bool = prim::GetAttr[name="use_sigmoid_ce"](%self)
                    %probs : Tensor = prim::If(%use_sigmoid_ce) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:565:8
                      block0():
                        %probs.1 : Tensor = aten::sigmoid(%scores.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:566:20
                        -> (%probs.1)
                      block1():
                        %probs.3 : Tensor = prim::CallFunction(%26, %scores.1, %23, %24, %25) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:568:20
                        -> (%probs.3)
                    %35 : Tensor[] = aten::split(%probs, %num_inst_per_image.1, %34) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:569:15
                    return (%35)
              
                }
              }
              submodules {
                module __torch__.torch.nn.modules.linear.___torch_mangle_43.Linear {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.linear.___torch_mangle_43.Linear,
                            %input.1 : Tensor):
                        %5 : Function = prim::Constant[name="linear"]()
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                        %6 : Tensor = prim::CallFunction(%5, %input.1, %weight, %bias) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/linear.py:103:15
                        return (%6)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.linear.___torch_mangle_44.Linear {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.linear.___torch_mangle_44.Linear,
                            %input.1 : Tensor):
                        %5 : Function = prim::Constant[name="linear"]()
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor = prim::GetAttr[name="bias"](%self)
                        %6 : Tensor = prim::CallFunction(%5, %input.1, %weight, %bias) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/linear.py:103:15
                        return (%6)
                  
                    }
                  }
                  submodules {
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.poolers.ROIPooler {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                output_size = (14, 14)
                min_level = 2
                max_level = 5
                canonical_level = 4
                canonical_box_size = 224
                level_poolers = <__torch__.torch.nn.modules.container.___torch_mangle_41.ModuleList object at 0xaaf9100>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.poolers.ROIPooler,
                        %x.1 : Tensor[],
                        %box_lists.1 : __torch__.detectron2.structures.boxes.Boxes[]):
                    %363 : bool = prim::Constant[value=0]()
                    %354 : Function = prim::Constant[name="nonzero_tuple"]()
                    %332 : Function = prim::Constant[name="assign_boxes_to_levels"]()
                    %234 : Function = prim::Constant[name="convert_boxes_to_pooler_format"]()
                    %65 : Function = prim::Constant[name="_create_zeros"]()
                    %54 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:237:33
                    %40 : str = prim::Constant[value="unequal value, x[0] batch dim 0 is {}, but box_list has length {}"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:233:11
                    %29 : str = prim::Constant[value="AssertionError: "]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:225:8
                    %24 : str = prim::Constant[value="unequal value, num_level_assignments={}, but x is list of {} Tensors"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:227:11
                    %level.1 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:35
                    %level.7 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:237:50
                    %level.13 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:253:8
                    %level.19 : int = prim::Constant[value=3]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:253:8
                    %level_poolers.1 : __torch__.torch.nn.modules.container.___torch_mangle_41.ModuleList = prim::GetAttr[name="level_poolers"](%self)
                    %num_level_assignments.1 : int = prim::CallMethod[name="__len__"](%level_poolers.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:220:32
                    %x.7 : Tensor[] = prim::unchecked_cast(%x.1)
                    %x.13 : Tensor[] = prim::unchecked_cast(%x.7)
                    %box_lists.7 : __torch__.detectron2.structures.boxes.Boxes[] = prim::unchecked_cast(%box_lists.1)
                    %20 : int = aten::len(%x.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:226:12
                    %22 : bool = aten::eq(%20, %num_level_assignments.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:226:12
                     = prim::If(%22) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:225:8
                      block0():
                        -> ()
                      block1():
                        %27 : int = aten::len(%x.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:228:35
                        %28 : str = aten::format(%24, %num_level_assignments.1, %27) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:227:11
                        %30 : str = aten::add(%29, %28) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:225:8
                         = prim::RaiseException(%30) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:225:8
                        -> ()
                    %33 : int = aten::len(%box_lists.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:15
                    %36 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:33
                    %37 : int = aten::size(%36, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:33
                    %38 : bool = aten::eq(%33, %37) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:15
                     = prim::If(%38) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:8
                      block0():
                        -> ()
                      block1():
                        %42 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:234:12
                        %43 : int = aten::size(%42, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:234:12
                        %45 : int = aten::len(%box_lists.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:234:26
                        %46 : str = aten::format(%40, %43, %45) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:233:11
                        %48 : str = aten::add(%29, %46) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:8
                         = prim::RaiseException(%48) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:231:8
                        -> ()
                    %51 : int = aten::len(%box_lists.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:236:11
                    %52 : bool = aten::eq(%51, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:236:11
                    %327 : Tensor = prim::If(%52) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:236:8
                      block0():
                        %56 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:237:39
                        %57 : int[] = aten::size(%56) # <string>:7:9
                        %59 : int = aten::__getitem__(%57, %level.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:237:39
                        %output_size.1 : (int, int) = prim::GetAttr[name="output_size"](%self)
                        %61 : int, %62 : int = prim::TupleUnpack(%output_size.1)
                        %64 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:237:73
                        %66 : Tensor = prim::CallFunction(%65, %54, %59, %61, %62, %64) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:237:19
                        -> (%66)
                      block1():
                        %pooler_fmt_boxes.13 : Tensor = prim::CallFunction(%234, %box_lists.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:239:27
                        %236 : bool = aten::eq(%num_level_assignments.1, %level.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:241:11
                        %402 : Tensor = prim::If(%236) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:241:8
                          block0():
                            %level_poolers.5 : __torch__.torch.nn.modules.container.___torch_mangle_41.ModuleList = prim::GetAttr[name="level_poolers"](%self)
                            %_0.3 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="0"](%level_poolers.5)
                            %249 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:242:41
                            %250 : Tensor = prim::CallMethod[name="forward"](%_0.3, %249, %pooler_fmt_boxes.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:242:19
                            -> (%250)
                          block1():
                            %min_level.5 : int = prim::GetAttr[name="min_level"](%self)
                            %max_level.5 : int = prim::GetAttr[name="max_level"](%self)
                            %canonical_box_size.5 : int = prim::GetAttr[name="canonical_box_size"](%self)
                            %canonical_level.5 : int = prim::GetAttr[name="canonical_level"](%self)
                            %level_assignments.13 : Tensor = prim::CallFunction(%332, %box_lists.7, %min_level.5, %max_level.5, %canonical_box_size.5, %canonical_level.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:244:28
                            %334 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:248:23
                            %335 : int[] = aten::size(%334) # <string>:7:9
                            %num_channels.7 : int = aten::__getitem__(%335, %level.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:248:23
                            %output_size.17 : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %output_size.21 : int = prim::TupleIndex(%output_size.17, %level.1)
                            %339 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:251:89
                            %output.15 : Tensor = prim::CallFunction(%65, %pooler_fmt_boxes.13, %num_channels.7, %output_size.21, %output_size.21, %339) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:251:17
                            %level_poolers.13 : __torch__.torch.nn.modules.container.___torch_mangle_41.ModuleList = prim::GetAttr[name="level_poolers"](%self)
                            %_0.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="0"](%level_poolers.13)
                            %_1.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="1"](%level_poolers.13)
                            %_2.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="2"](%level_poolers.13)
                            %_3.11 : __torch__.detectron2.layers.roi_align.ROIAlign = prim::GetAttr[name="3"](%level_poolers.13)
                            %353 : Tensor = aten::eq(%level_assignments.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:33
                            %355 : Tensor[] = prim::CallFunction(%354, %353) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %inds.55 : Tensor = aten::__getitem__(%355, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %357 : Tensor?[] = prim::ListConstruct(%inds.55)
                            %pooler_fmt_boxes_level.31 : Tensor = aten::index(%pooler_fmt_boxes.13, %357) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:255:37
                            %360 : Tensor = aten::__getitem__(%x.13, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:46
                            %361 : Tensor = prim::CallMethod[name="forward"](%_0.11, %360, %pooler_fmt_boxes_level.31) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:39
                            %362 : Tensor?[] = prim::ListConstruct(%inds.55)
                            %364 : Tensor = aten::index_put_(%output.15, %362, %361, %363) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:12
                            %365 : Tensor = aten::eq(%level_assignments.13, %level.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:33
                            %367 : Tensor[] = prim::CallFunction(%354, %365) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %inds.59 : Tensor = aten::__getitem__(%367, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %369 : Tensor?[] = prim::ListConstruct(%inds.59)
                            %pooler_fmt_boxes_level.35 : Tensor = aten::index(%pooler_fmt_boxes.13, %369) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:255:37
                            %372 : Tensor = aten::__getitem__(%x.13, %level.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:46
                            %373 : Tensor = prim::CallMethod[name="forward"](%_1.11, %372, %pooler_fmt_boxes_level.35) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:39
                            %374 : Tensor?[] = prim::ListConstruct(%inds.59)
                            %376 : Tensor = aten::index_put_(%output.15, %374, %373, %363) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:12
                            %377 : Tensor = aten::eq(%level_assignments.13, %level.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:33
                            %379 : Tensor[] = prim::CallFunction(%354, %377) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %inds.63 : Tensor = aten::__getitem__(%379, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %381 : Tensor?[] = prim::ListConstruct(%inds.63)
                            %pooler_fmt_boxes_level.39 : Tensor = aten::index(%pooler_fmt_boxes.13, %381) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:255:37
                            %384 : Tensor = aten::__getitem__(%x.13, %level.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:46
                            %385 : Tensor = prim::CallMethod[name="forward"](%_2.11, %384, %pooler_fmt_boxes_level.39) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:39
                            %386 : Tensor?[] = prim::ListConstruct(%inds.63)
                            %388 : Tensor = aten::index_put_(%output.15, %386, %385, %363) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:12
                            %389 : Tensor = aten::eq(%level_assignments.13, %level.19) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:33
                            %391 : Tensor[] = prim::CallFunction(%354, %389) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %inds.67 : Tensor = aten::__getitem__(%391, %level.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:254:19
                            %393 : Tensor?[] = prim::ListConstruct(%inds.67)
                            %pooler_fmt_boxes_level.43 : Tensor = aten::index(%pooler_fmt_boxes.13, %393) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:255:37
                            %396 : Tensor = aten::__getitem__(%x.13, %level.19) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:46
                            %397 : Tensor = prim::CallMethod[name="forward"](%_3.11, %396, %pooler_fmt_boxes_level.43) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:39
                            %398 : Tensor?[] = prim::ListConstruct(%inds.67)
                            %400 : Tensor = aten::index_put_(%output.15, %398, %397, %363) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/poolers.py:257:12
                            -> (%output.15)
                        -> (%402)
                    return (%327)
              
                }
              }
              submodules {
                module __torch__.torch.nn.modules.container.___torch_mangle_41.ModuleList {
                  parameters {
                  }
                  attributes {
                    _is_full_backward_hook = None
                    0 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x62a1c30>
                    1 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x6299500>
                    2 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x625a050>
                    3 = <__torch__.detectron2.layers.roi_align.ROIAlign object at 0x62a07b0>
                  }
                  methods {
                    method __len__ {
                      graph(%self : __torch__.torch.nn.modules.container.___torch_mangle_41.ModuleList):
                        %1 : int = prim::Constant[value=4]() # <string>:2:10
                        return (%1)
                  
                    }
                  }
                  submodules {
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (14, 14)
                        spatial_scale = 0.25
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %46 : Function = prim::Constant[name="roi_align"]()
                            %37 : NoneType = prim::Constant()
                            %60 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %22 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%22) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %34 : int = prim::dtype(%input)
                            %38 : Tensor = aten::to(%rois.1, %34, %15, %15, %37) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %43 : int, %44 : int = prim::TupleUnpack(%output_size)
                            %45 : int[] = prim::ListConstruct(%43, %44)
                            %47 : Tensor = prim::CallFunction(%46, %input, %38, %45, %spatial_scale, %sampling_ratio, %aligned) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:58:15
                            return (%47)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (14, 14)
                        spatial_scale = 0.125
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %46 : Function = prim::Constant[name="roi_align"]()
                            %37 : NoneType = prim::Constant()
                            %60 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %22 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%22) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %34 : int = prim::dtype(%input)
                            %38 : Tensor = aten::to(%rois.1, %34, %15, %15, %37) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %43 : int, %44 : int = prim::TupleUnpack(%output_size)
                            %45 : int[] = prim::ListConstruct(%43, %44)
                            %47 : Tensor = prim::CallFunction(%46, %input, %38, %45, %spatial_scale, %sampling_ratio, %aligned) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:58:15
                            return (%47)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (14, 14)
                        spatial_scale = 0.0625
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %46 : Function = prim::Constant[name="roi_align"]()
                            %37 : NoneType = prim::Constant()
                            %60 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %22 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%22) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %34 : int = prim::dtype(%input)
                            %38 : Tensor = aten::to(%rois.1, %34, %15, %15, %37) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %43 : int, %44 : int = prim::TupleUnpack(%output_size)
                            %45 : int[] = prim::ListConstruct(%43, %44)
                            %47 : Tensor = prim::CallFunction(%46, %input, %38, %45, %spatial_scale, %sampling_ratio, %aligned) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:58:15
                            return (%47)
                      
                        }
                      }
                      submodules {
                      }
                    }
                    module __torch__.detectron2.layers.roi_align.ROIAlign {
                      parameters {
                      }
                      attributes {
                        _is_full_backward_hook = None
                        output_size = (14, 14)
                        spatial_scale = 0.03125
                        sampling_ratio = 0
                        aligned = True
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.detectron2.layers.roi_align.ROIAlign,
                                %input.1 : Tensor,
                                %rois.1 : Tensor):
                            %46 : Function = prim::Constant[name="roi_align"]()
                            %37 : NoneType = prim::Constant()
                            %60 : str = prim::Constant[value="AssertionError: "]()
                            %15 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %6 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:29
                            %10 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:45
                            %12 : int = prim::Constant[value=5]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:51
                            %5 : int = aten::dim(%rois.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %7 : bool = aten::eq(%5, %6) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                            %16 : bool = prim::If(%7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:15
                              block0():
                                %11 : int = aten::size(%rois.1, %10) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                %13 : bool = aten::eq(%11, %12) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:35
                                -> (%13)
                              block1():
                                -> (%15)
                             = prim::If(%16) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                              block0():
                                -> ()
                              block1():
                                 = prim::RaiseException(%60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:55:8
                                -> ()
                            %22 : bool = prim::is_quantized(%input.1)
                            %input : Tensor = prim::If(%22) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:56:8
                              block0():
                                %input.7 : Tensor = aten::dequantize(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:57:20
                                -> (%input.7)
                              block1():
                                -> (%input.1)
                            %34 : int = prim::dtype(%input)
                            %38 : Tensor = aten::to(%rois.1, %34, %15, %15, %37) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:60:12
                            %output_size : (int, int) = prim::GetAttr[name="output_size"](%self)
                            %spatial_scale : float = prim::GetAttr[name="spatial_scale"](%self)
                            %sampling_ratio : int = prim::GetAttr[name="sampling_ratio"](%self)
                            %aligned : bool = prim::GetAttr[name="aligned"](%self)
                            %43 : int, %44 : int = prim::TupleUnpack(%output_size)
                            %45 : int[] = prim::ListConstruct(%43, %44)
                            %47 : Tensor = prim::CallFunction(%46, %input, %38, %45, %spatial_scale, %sampling_ratio, %aligned) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/roi_align.py:58:15
                            return (%47)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
              }
            }
            module __torch__.detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead {
              parameters {
              }
              attributes {
                _is_full_backward_hook = None
                vis_period = 0
                loss_weight = 1.
                mask_fcn1 = <__torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d object at 0xaa4ab10>
                mask_fcn2 = <__torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d object at 0x84e1a50>
                mask_fcn3 = <__torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d object at 0x62bc360>
                mask_fcn4 = <__torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d object at 0x6253750>
                deconv = <__torch__.torch.nn.modules.conv.ConvTranspose2d object at 0xaaf89d0>
                deconv_relu = <__torch__.torch.nn.modules.activation.ReLU object at 0x6301220>
                predictor = <__torch__.detectron2.layers.wrappers.___torch_mangle_45.Conv2d object at 0x630f590>
              }
              methods {
                method forward {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead,
                        %x.1 : Tensor,
                        %instances.1 : __torch__.detectron2.export.torchscript_patch1.ScriptedInstances1[]):
                    %10 : Function = prim::Constant[name="mask_rcnn_inference"]()
                    %x.5 : Tensor = prim::CallMethod[name="layers"](%self, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/mask_head.py:197:12
                    %11 : NoneType = prim::CallFunction(%10, %x.5, %instances.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/mask_head.py:201:12
                    return (%instances.1)
              
                }
                method layers {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead,
                        %x.1 : Tensor):
                    %30 : NoneType = prim::Constant()
                    %mask_fcn1 : __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d = prim::GetAttr[name="mask_fcn1"](%self)
                    %mask_fcn2 : __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d = prim::GetAttr[name="mask_fcn2"](%self)
                    %mask_fcn3 : __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d = prim::GetAttr[name="mask_fcn3"](%self)
                    %mask_fcn4 : __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d = prim::GetAttr[name="mask_fcn4"](%self)
                    %deconv : __torch__.torch.nn.modules.conv.ConvTranspose2d = prim::GetAttr[name="deconv"](%self)
                    %deconv_relu : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="deconv_relu"](%self)
                    %predictor : __torch__.detectron2.layers.wrappers.___torch_mangle_45.Conv2d = prim::GetAttr[name="predictor"](%self)
                    %x.5 : Tensor = prim::CallMethod[name="forward"](%mask_fcn1, %x.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/mask_head.py:289:16
                    %x.9 : Tensor = prim::CallMethod[name="forward"](%mask_fcn2, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/mask_head.py:289:16
                    %x.13 : Tensor = prim::CallMethod[name="forward"](%mask_fcn3, %x.9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/mask_head.py:289:16
                    %x.17 : Tensor = prim::CallMethod[name="forward"](%mask_fcn4, %x.13) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/mask_head.py:289:16
                    %x.21 : Tensor = prim::CallMethod[name="forward"](%deconv, %x.17, %30) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/mask_head.py:289:16
                    %x.25 : Tensor = prim::CallMethod[name="forward"](%deconv_relu, %x.21) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/mask_head.py:289:16
                    %x.29 : Tensor = prim::CallMethod[name="forward"](%predictor, %x.25) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/modeling/roi_heads/mask_head.py:289:16
                    return (%x.29)
              
                }
                method __len__ {
                  graph(%self : __torch__.detectron2.modeling.roi_heads.mask_head.MaskRCNNConvUpsampleHead):
                    %1 : int = prim::Constant[value=7]() # <string>:2:10
                    return (%1)
              
                }
              }
              submodules {
                module __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = <__torch__.torch.nn.modules.activation.ReLU object at 0x61b7060>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %activation : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="activation"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%activation, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:117:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.activation.ReLU {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                                %input.1 : Tensor):
                            %4 : Function = prim::Constant[name="relu"]()
                            %3 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:37
                            %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:15
                            return (%5)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = <__torch__.torch.nn.modules.activation.ReLU object at 0xaaeb260>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %activation : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="activation"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%activation, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:117:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.activation.ReLU {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                                %input.1 : Tensor):
                            %4 : Function = prim::Constant[name="relu"]()
                            %3 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:37
                            %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:15
                            return (%5)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = <__torch__.torch.nn.modules.activation.ReLU object at 0x629f580>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %activation : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="activation"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%activation, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:117:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.activation.ReLU {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                                %input.1 : Tensor):
                            %4 : Function = prim::Constant[name="relu"]()
                            %3 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:37
                            %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:15
                            return (%5)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [1, 1, 1, 1]
                    norm = None
                    activation = <__torch__.torch.nn.modules.activation.ReLU object at 0x1213c670>
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_39.Conv2d,
                            %x.1 : Tensor):
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%8, %8)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        %activation : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="activation"](%self)
                        %x.9 : Tensor = prim::CallMethod[name="forward"](%activation, %x.5) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:117:16
                        return (%x.9)
                  
                    }
                  }
                  submodules {
                    module __torch__.torch.nn.modules.activation.ReLU {
                      parameters {
                      }
                      attributes {
                        training = False
                        _is_full_backward_hook = None
                      }
                      methods {
                        method forward {
                          graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                                %input.1 : Tensor):
                            %4 : Function = prim::Constant[name="relu"]()
                            %3 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:37
                            %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:15
                            return (%5)
                      
                        }
                      }
                      submodules {
                      }
                    }
                  }
                }
                module __torch__.torch.nn.modules.conv.ConvTranspose2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = True
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.conv.ConvTranspose2d,
                            %input.1 : Tensor,
                            %output_size.1 : int[]?):
                        %24 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:921:77
                        %18 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:921:45
                        %15 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:921:32
                        %27 : int[] = prim::ListConstruct(%15, %15)
                        %28 : int[] = prim::ListConstruct(%18, %18)
                        %29 : int[] = prim::ListConstruct(%15, %15)
                        %30 : int[] = prim::ListConstruct(%24, %24)
                        %output_padding.1 : int[] = prim::CallMethod[name="_output_padding"](%self, %input.1, %output_size.1, %27, %28, %29, %30) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:920:25
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %46 : int[] = prim::ListConstruct(%15, %15)
                        %47 : int[] = prim::ListConstruct(%18, %18)
                        %48 : int[] = prim::ListConstruct(%24, %24)
                        %49 : Tensor = aten::conv_transpose2d(%input.1, %weight, %bias, %46, %47, %output_padding.1, %24, %48) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:923:15
                        return (%49)
                  
                    }
                    method _output_padding {
                      graph(%self : __torch__.torch.nn.modules.conv.ConvTranspose2d,
                            %input.1 : Tensor,
                            %output_size.1 : int[]?,
                            %stride.1 : int[],
                            %padding.1 : int[],
                            %kernel_size.1 : int[],
                            %dilation.1 : int[]?):
                        %126 : str = prim::Constant[value="requested an output size of {}, but valid sizes range from {} to {} (for an input of {})"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:638:24
                        %54 : bool = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:625:12
                        %41 : str = prim::Constant[value="output_size must have {} or {} elements (got {})"]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:620:20
                        %10 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:613:26
                        %8 : NoneType = prim::Constant() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:612:26
                        %19 : int = prim::Constant[value=2]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:615:30
                        %60 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:626:49
                        %9 : bool = aten::__is__(%output_size.1, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:612:11
                        %ret : int[] = prim::If(%9) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:612:8
                          block0():
                            %ret.1 : int[] = prim::ListConstruct(%10, %10)
                            -> (%ret.1)
                          block1():
                            %output_size.7 : int[] = prim::unchecked_cast(%output_size.1)
                            %18 : int = aten::dim(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:615:16
                            %k.1 : int = aten::sub(%18, %19) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:615:16
                            %22 : int = aten::len(%output_size.7) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:616:15
                            %24 : int = aten::add(%k.1, %19) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:616:35
                            %25 : bool = aten::eq(%22, %24) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:616:15
                            %output_size.47 : int[] = prim::If(%25) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:616:12
                              block0():
                                %output_size.15 : int[] = aten::slice(%output_size.7, %19, %8, %60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:617:30
                                -> (%output_size.15)
                              block1():
                                -> (%output_size.7)
                            %37 : int = aten::len(%output_size.47) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:618:15
                            %39 : bool = aten::ne(%37, %k.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:618:15
                             = prim::If(%39) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:618:12
                              block0():
                                %44 : int = aten::add(%k.1, %19) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:621:31
                                %46 : int = aten::len(%output_size.47) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:621:38
                                %47 : str = aten::format(%41, %k.1, %44, %46) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:620:20
                                 = prim::RaiseException(%47) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:619:16
                                -> ()
                              block1():
                                -> ()
                            %min_sizes.1 : int[] = prim::ListConstruct()
                            %max_sizes.1 : int[] = prim::ListConstruct()
                            %dilation.17 : int[]? = prim::Loop(%k.1, %54, %dilation.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:625:12
                              block0(%d.1 : int, %dilation.15 : int[]?):
                                %58 : int = aten::add(%d.1, %19) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:626:40
                                %59 : int = aten::size(%input.1, %58) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:626:29
                                %61 : int = aten::sub(%59, %60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:626:29
                                %64 : int = aten::__getitem__(%stride.1, %d.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:626:54
                                %65 : int = aten::mul(%61, %64) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:626:29
                                %68 : int = aten::__getitem__(%padding.1, %d.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:627:32
                                %69 : int = aten::mul(%19, %68) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:627:28
                                %70 : int = aten::sub(%65, %69) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:626:29
                                %73 : bool = aten::__isnot__(%dilation.15, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:628:44
                                %80 : int, %dilation.13 : int[]? = prim::If(%73) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:628:29
                                  block0():
                                    %dilation.7 : int[] = prim::unchecked_cast(%dilation.15)
                                    %79 : int = aten::__getitem__(%dilation.7, %d.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:628:29
                                    -> (%79, %dilation.7)
                                  block1():
                                    -> (%60, %dilation.15)
                                %83 : int = aten::__getitem__(%kernel_size.1, %d.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:628:76
                                %84 : int = aten::sub(%83, %60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:628:76
                                %85 : int = aten::mul(%80, %84) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:628:29
                                %86 : int = aten::add(%70, %85) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:626:29
                                %dim_size.1 : int = aten::add(%86, %60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:626:29
                                %90 : int[] = aten::append(%min_sizes.1, %dim_size.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:629:16
                                %94 : int = aten::__getitem__(%min_sizes.1, %d.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:630:33
                                %97 : int = aten::__getitem__(%stride.1, %d.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:630:48
                                %98 : int = aten::add(%94, %97) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:630:33
                                %99 : int = aten::sub(%98, %60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:630:33
                                %100 : int[] = aten::append(%max_sizes.1, %99) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:630:16
                                -> (%54, %dilation.13)
                            %102 : int = aten::len(%output_size.47) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:632:27
                             = prim::Loop(%102, %54) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:632:12
                              block0(%i.1 : int):
                                %size.1 : int = aten::__getitem__(%output_size.47, %i.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:633:23
                                %min_size.1 : int = aten::__getitem__(%min_sizes.1, %i.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:634:27
                                %max_size.1 : int = aten::__getitem__(%max_sizes.1, %i.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:635:27
                                %118 : bool = aten::lt(%size.1, %min_size.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:636:19
                                %125 : bool = prim::If(%118) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:636:19
                                  block0():
                                    -> (%54)
                                  block1():
                                    %123 : bool = aten::gt(%size.1, %max_size.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:636:38
                                    -> (%123)
                                 = prim::If(%125) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:636:16
                                  block0():
                                    %131 : int[] = aten::size(%input.1) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:640:63
                                    %134 : int[] = aten::slice(%131, %19, %8, %60) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:640:63
                                    %135 : str = aten::format(%126, %output_size.47, %min_sizes.1, %max_sizes.1, %134) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:638:24
                                     = prim::RaiseException(%135) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:637:20
                                    -> ()
                                  block1():
                                    -> ()
                                -> (%54)
                            %res.1 : int[] = prim::ListConstruct()
                             = prim::Loop(%k.1, %54) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:643:12
                              block0(%d.17 : int):
                                %146 : int = aten::__getitem__(%output_size.47, %d.17) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:644:27
                                %149 : int = aten::__getitem__(%min_sizes.1, %d.17) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:644:44
                                %150 : int = aten::sub(%146, %149) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:644:27
                                %151 : int[] = aten::append(%res.1, %150) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/conv.py:644:16
                                -> (%54)
                            -> (%res.1)
                        return (%ret)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.torch.nn.modules.activation.ReLU {
                  parameters {
                  }
                  attributes {
                    training = False
                    _is_full_backward_hook = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.torch.nn.modules.activation.ReLU,
                            %input.1 : Tensor):
                        %4 : Function = prim::Constant[name="relu"]()
                        %3 : bool = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:37
                        %5 : Tensor = prim::CallFunction(%4, %input.1, %3) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/torch/nn/modules/activation.py:98:15
                        return (%5)
                  
                    }
                  }
                  submodules {
                  }
                }
                module __torch__.detectron2.layers.wrappers.___torch_mangle_45.Conv2d {
                  parameters {
                    weight = ...
                    bias = ...
                  }
                  attributes {
                    weight = ...
                    bias = ...
                    training = False
                    _is_full_backward_hook = None
                    transposed = False
                    _reversed_padding_repeated_twice = [0, 0, 0, 0]
                    norm = None
                    activation = None
                  }
                  methods {
                    method forward {
                      graph(%self : __torch__.detectron2.layers.wrappers.___torch_mangle_45.Conv2d,
                            %x.1 : Tensor):
                        %11 : int = prim::Constant[value=0]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:52
                        %8 : int = prim::Constant[value=1]() # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:112:39
                        %weight : Tensor = prim::GetAttr[name="weight"](%self)
                        %bias : Tensor? = prim::GetAttr[name="bias"](%self)
                        %18 : int[] = prim::ListConstruct(%8, %8)
                        %19 : int[] = prim::ListConstruct(%11, %11)
                        %20 : int[] = prim::ListConstruct(%8, %8)
                        %x.5 : Tensor = aten::conv2d(%x.1, %weight, %bias, %18, %19, %20, %8) # /home/aicenter/pyven/pytorch/lib/python3.8/site-packages/detectron2/layers/wrappers.py:111:12
                        return (%x.5)
                  
                    }
                  }
                  submodules {
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}
